{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Individuelle Balkonm\u00f6bel \u2013 Natureform","text":"<p>Dieses Projekt verfolgt das Ziel, ein Business aufzubauen, bei dem Kund:innen ihre Balkonm\u00f6bel individuell online konfigurieren und direkt bestellen k\u00f6nnen. \u00dcber einen browserbasierten Konfigurator werden die Balkonma\u00dfe eingegeben und die M\u00f6bel nach Wunsch zusammengestellt.  </p> <p>Aus jeder Bestellung wird automatisch eine St\u00fcckliste generiert, die anschlie\u00dfend in eine Produktionsliste \u00fcberf\u00fchrt wird. Diese Produktionsliste enth\u00e4lt alle notwendigen Ma\u00dfe und Bearbeitungsschritte (z. B. Zuschnitt, Bohrungen, Fr\u00e4sungen, Lasergravuren). So kann die Fertigung weitgehend automatisiert erfolgen.  </p> <p>Dar\u00fcber hinaus soll eine individuelle Aufbauanleitung f\u00fcr jede Bestellung erstellt werden, z. B. automatisch generiert mit LaTeX.  </p>"},{"location":"#projektstruktur","title":"Projektstruktur","text":"<p>Das Projekt ist in mehrere Teilbereiche gegliedert, die jeweils in eigenen Markdown-Dateien dokumentiert werden:</p> <ul> <li> <p>Visionboard </p> </li> <li> <p>\ud83d\udcc8 Marktstrategie &amp; Analyse   Zielgruppe, Marktpotenzial, USP, Just-in-Time-Fertigung, Wettbewerbsanalyse.</p> </li> <li> <p>\ud83d\udcbb Konfigurator-Software   Konzept f\u00fcr den Web-basierten M\u00f6belkonfigurator, Datenfluss von Bestellung bis Fertigung.</p> </li> <li> <p>\u2699\ufe0f Fertigung &amp; Maschinen   Analyse der ben\u00f6tigten Maschinen, Produktionsschritte, Automatisierungsm\u00f6glichkeiten.</p> </li> </ul>"},{"location":"#zielsetzung","title":"Zielsetzung","text":"<ul> <li>Entwicklung eines End-to-End-Systems: Von der Online-Bestellung \u00fcber die Produktion bis hin zur Lieferung.  </li> <li>Automatisierung von Fertigungsschritten und Dokumentenerstellung.  </li> <li>Aufbau eines skalierbaren Businessmodells im Bereich ma\u00dfgefertigter Balkonm\u00f6bel.</li> </ul> <p>\u270d\ufe0f Weitere Dokumentationen folgen in den jeweiligen Unterseiten.</p>"},{"location":"NatureForm%20Overview/","title":"NatureForm Overview","text":""},{"location":"NatureForm%20Overview/#documentation-overview","title":"Documentation Overview","text":"<ul> <li>Home</li> </ul>"},{"location":"NatureForm%20Overview/#frontend","title":"Frontend","text":""},{"location":"NatureForm%20Overview/#model-configurator","title":"Model Configurator","text":"<ul> <li>Overview</li> <li>Collision</li> <li>WrappingLogic</li> <li>Silhouette Extractor</li> </ul>"},{"location":"NatureForm%20Overview/#other-frontend-modules","title":"Other Frontend Modules","text":"<ul> <li>Floorplan Configurator</li> <li>Framework</li> </ul>"},{"location":"NatureForm%20Overview/#threejs","title":"ThreeJS","text":"<ul> <li>Overview</li> <li>ThreeJS Backend</li> </ul>"},{"location":"NatureForm%20Overview/#cad-to-threejs","title":"Cad to ThreeJS","text":"<ul> <li>Overview</li> <li>GLB + Parameters</li> <li>Object Wrapping</li> <li>Feature Tree Transpiling</li> </ul>"},{"location":"NatureForm%20Overview/#fertigung","title":"Fertigung","text":"<ul> <li>Overview</li> <li>Maschinen</li> </ul>"},{"location":"NatureForm%20Overview/#marktstrategie-analyse","title":"Marktstrategie &amp; Analyse","text":"<ul> <li>Marktstrategie &amp; Analyse</li> <li>Kundenbedeurfnisse</li> <li>Zielgruppe</li> </ul>"},{"location":"NatureForm%20Overview/#konkurrenzanalyse","title":"Konkurrenzanalyse","text":"<ul> <li>Ikea</li> </ul>"},{"location":"VisionBoard/","title":"Vision Board \u2013 Referenzanalyse &amp; Inspiration","text":"<p>Status: Recherche &amp; Benchmarking Thema: Entwicklung eines Konfigurators f\u00fcr Balkonm\u00f6bel</p> <p>Dieses Dokument dient als Inspirationsquelle und technische Referenz. Es analysiert bestehende L\u00f6sungen hinsichtlich User Experience (UX), technischer Machbarkeit und Design, um Anforderungen f\u00fcr das eigene Projekt abzuleiten.</p>"},{"location":"VisionBoard/#referenz-1-gridfinity-generator","title":"Referenz 1: Gridfinity Generator","text":"<p>Link: https://gridfinitygenerator.com/en</p> <p>Beschreibung: Ein spezialisierter, webbasierter Generator f\u00fcr das \"Gridfinity\"-Ordnungssystem. Nutzer k\u00f6nnen Parameter wie Dimensionen, Stapelbarkeit und F\u00e4cheraufteilung definieren und erhalten ein druckbares 3D-Modell.</p> <p></p> <p>Analyse: St\u00e4rken * Fokus auf Parameter: Die Eingabemasken sind sauber von der 3D-Vorschau getrennt. * Performance: Schnelles Rendering der Geometrie bei Parameter\u00e4nderungen. * Zweckm\u00e4\u00dfigkeit: Sehr \"werkzeugorientiertes\" Design, das effizient zum Ergebnis f\u00fchrt.</p> <p>Analyse: Schw\u00e4chen * Visuell sehr n\u00fcchtern (Dark Mode Utility-Style), wenig emotionale Ansprache f\u00fcr M\u00f6belkunden.</p> <p>Transfer-Potenzial (To-Do): * \u00dcbernahme der Logik f\u00fcr parametrische Gr\u00f6\u00dfen\u00e4nderungen (Breite/H\u00f6he/Tiefe). * Implementierung einer Echtzeit-Vorschau, die sich instantan aktualisiert.</p>"},{"location":"VisionBoard/#referenz-2-perplexing-labs-gridfinity","title":"Referenz 2: Perplexing Labs Gridfinity","text":"<p>Link: https://gridfinity.perplexinglabs.com/</p> <p>Beschreibung: Eine alternative Implementierung eines Gridfinity-Konfigurators, der eine andere Herangehensweise an die UI/UX w\u00e4hlt und tiefere Konfigurationsm\u00f6glichkeiten bietet.</p> <p></p> <p>Analyse: St\u00e4rken * Umfangreiche Optionen: Zeigt, wie viele Parameter (bis ins Detail) dem Nutzer angeboten werden k\u00f6nnen, ohne die \u00dcbersicht komplett zu verlieren. * Kamerasteuerung: Intuitive Navigation im 3D-Raum.</p> <p>Analyse: Schw\u00e4chen * F\u00fcr Endkunden im M\u00f6belbereich evtl. zu technisch (\"Engineering-Look\").</p> <p>Transfer-Potenzial (To-Do): * Evaluation der verwendeten Bibliotheken f\u00fcr das Handling komplexer Geometrie-Updates. * Abw\u00e4gung: Wie viele technische Details (z.B. Wandst\u00e4rken) muss der Endkunde sehen?</p>"},{"location":"VisionBoard/#referenz-3-parametrische-3d-assets-boytchev","title":"Referenz 3: Parametrische 3D-Assets (Boytchev)","text":"<p>Link: https://boytchev.github.io/3d-assets/</p> <p>Beschreibung: Demonstration verschiedener geometrischer Objekte, die \u00fcber Schieberegler in Echtzeit modifiziert werden k\u00f6nnen.</p> <p>Analyse: St\u00e4rken * Intuitive Steuerung: Parametrische Anpassungen sind sofort verst\u00e4ndlich. * Tech-Demo: Exzellenter Proof-of-Concept f\u00fcr browserbasierte Geometrieanpassung.</p> <p>Analyse: Schw\u00e4chen * Reine Tech-Demo ohne UX-Konzept f\u00fcr Endanwender. * Optik wirkt abstrakt und mathematisch.</p> <p>Transfer-Potenzial (To-Do): * Oberfl\u00e4che (UI) muss emotionaler gestaltet werden (Materialien, Licht). * Abstrakte Geometrie muss durch konkrete M\u00f6belkomponenten ersetzt werden. * Anbindung an eine Datenbank f\u00fcr Preiskalkulation notwendig.</p>"},{"location":"VisionBoard/#referenz-4-csg-house-codesandbox","title":"Referenz 4: CSG House (CodeSandbox)","text":"<p>Link: https://codesandbox.io/p/sandbox/csg-house-y52tmt</p> <p>Beschreibung: Ein Architektur-Modell, das Constructive Solid Geometry (CSG) nutzt, um Fenster und T\u00fcren interaktiv im Bauk\u00f6rper zu verschieben (inkl. Sourcecode).</p> <p></p> <p>Analyse: St\u00e4rken * CSG-Einsatz: Zeigt sehr gut, wie Boolesche Operationen (Subtraktion von Volumen) im Browser funktionieren. * Interaktivit\u00e4t: Drag &amp; Drop von Elementen am Modell.</p> <p>Analyse: Schw\u00e4chen * Modell (Haus) nicht direkt auf M\u00f6bel \u00fcbertragbar. * Kein visuelles Design (\"Rohzustand\").</p> <p>Transfer-Potenzial (To-Do): * Adaption f\u00fcr M\u00f6bel: z.B. Ausschnitte f\u00fcr Kabelkan\u00e4le oder Griffe. * Erweiterung um Export-Funktionen (St\u00fccklisten/BOM).</p>"},{"location":"VisionBoard/#referenz-5-bang-olufsen-konfigurator","title":"Referenz 5: Bang &amp; Olufsen Konfigurator","text":"<p>Link: https://www.bang-olufsen.com/de/int/composer?page=productselection</p> <p>Beschreibung: High-End Konfigurator f\u00fcr Lautsprecher, der Design und Funktionalit\u00e4t nahtlos verbindet.</p> <p>Analyse: St\u00e4rken * Premium UX: Hochwertige Inszenierung, fl\u00fcssige Animationen. * Branding: Das Markenimage wird durch den Konfigurator gest\u00e4rkt.</p> <p>Analyse: Schw\u00e4chen * Hohe Entwicklungskomplexit\u00e4t und Kosten.</p> <p>Transfer-Potenzial (To-Do): * Zielsetzung f\u00fcr das \"Look &amp; Feel\" der finalen Anwendung. * Integration mit Backend-Systemen (Fertigung/Bestellung) ist hier essentiell gel\u00f6st.</p>"},{"location":"VisionBoard/#referenz-6-hulo-tischkonfigurator","title":"Referenz 6: Hulo Tischkonfigurator","text":"<p>Link: https://hulo.be/configurator/</p> <p>Beschreibung: Ein dedizierter Konfigurator f\u00fcr Tische. Technische Hintergr\u00fcnde werden hier diskutiert: discourse.threejs.org.</p> <p></p> <p>Analyse: St\u00e4rken * Domain-Fit: Passt thematisch genau (M\u00f6bel). * Simplicity: Einfache UX, Fokus auf Ma\u00dfe und Materialien.</p> <p>Analyse: Schw\u00e4chen * Auf einen einzigen M\u00f6beltyp (Tisch) beschr\u00e4nkt. * Teilweise noch etwas technisch in der Anmutung.</p> <p>Transfer-Potenzial (To-Do): * Erweiterung des Konzepts auf modulare Balkonm\u00f6bel (B\u00e4nke, Stauraum). * Optimierung der Usability f\u00fcr mobile Endger\u00e4te.</p>"},{"location":"VisionBoard/#referenz-7-ikea-home-planner","title":"Referenz 7: IKEA Home Planner","text":"<p>Link: https://www.ikea.com/de/de/planner/</p> <p></p> <p>Beschreibung: Der Industriestandard f\u00fcr Raum- und M\u00f6belplanung im Massenmarkt.</p> <p>Analyse: St\u00e4rken * Bekanntheit: Nutzer kennen und verstehen das Bedienkonzept (geringe Lernkurve). * E-Commerce: Nahtlose Integration in den Warenkorb.</p> <p>Analyse: Schw\u00e4chen * Feature-Overload: F\u00fcr einen Nischen-Konfigurator oft zu m\u00e4chtig und komplex.</p> <p>Transfer-Potenzial (To-Do): * Reduktion: Fokus auf Individualisierung statt Massenplanung. * Spezialisierung auf den Kontext \"Balkon\" (Wetterfestigkeit, begrenzter Platz).</p>"},{"location":"VisionBoard/#referenz-8-thuma-beds","title":"Referenz 8: Thuma Beds","text":"<p>Link: https://www.ikea.com/de/de/planner/</p> <p>![[Pasted image 20260106142848.png]]</p> <p>Beschreibung: Bett Konfigurator mit einfacher Montage</p>"},{"location":"VisionBoard/#technische-basis","title":"Technische Basis","text":"<p>Die meisten der analysierten Konfiguratoren basieren auf three.js (WebGL). Aus diesem Grund erfolgt im Dokument Technologie-Stack: three.js eine detaillierte Betrachtung des Frameworks.</p>"},{"location":"Wissensdatenbank/","title":"Wissensdatenbank","text":""},{"location":"Wissensdatenbank/#externe-ressourcen","title":"Externe Ressourcen","text":"<ul> <li>Harvard Business School: Business Models (Publication 11-091)</li> </ul>"},{"location":"Fertigung/Fertigung/","title":"Fertigung \u2013 Prozessbeschreibung","text":"<p>Die Fertigung der individuellen Balkonm\u00f6bel erfolgt in mehreren automatisierten Schritten. Ziel ist es, aus der Bestellung eine exakte Produktionsliste abzuleiten, die direkt als Input f\u00fcr die Maschinen dient.  </p>"},{"location":"Fertigung/Fertigung/#prozesskette","title":"Prozesskette","text":"<p>Die wesentlichen Prozessschritte sind:</p> <ol> <li>Bestellung &amp; Konfiguration </li> <li>Kund:in gibt Balkonma\u00dfe und M\u00f6belw\u00fcnsche online ein.  </li> <li> <p>Automatische Generierung der St\u00fcck- und Produktionsliste.</p> </li> <li> <p>Materialbereitstellung </p> </li> <li> <p>Auswahl und Bereitstellung von Holzlatten und Vierkanth\u00f6lzern.  </p> </li> <li> <p>Zuschnitt </p> </li> <li>S\u00e4gen der Bretter und Vierkanth\u00f6lzern auf exakte L\u00e4nge.  </li> <li> <p>Optimierung des Verschnitts (Materialeffizienz).</p> </li> <li> <p>Bearbeitung </p> </li> <li>Bohren von L\u00f6chern f\u00fcr Schraubverbindungen.  </li> <li>Fr\u00e4sen von Taschen und Nuten.  </li> <li> <p>Lasergravuren (z. B. Logo, Markierungen, Zusammenbauhinweise bei nicht sichtbaren Teilen).  </p> </li> <li> <p>Qualit\u00e4tskontrolle </p> </li> <li>Pr\u00fcfung der Ma\u00dfhaltigkeit und Vollst\u00e4ndigkeit.  </li> <li> <p>Automatische Kennzeichnung oder Sortierung fehlerhafter Teile.</p> </li> <li> <p>Verpackung &amp; Versand </p> </li> <li>Zuordnung der Bretter zur jeweiligen Bestellung.  </li> <li>Verpackung und Etikettierung.  </li> <li>Versandbereitstellung.</li> </ol>"},{"location":"Fertigung/Fertigung/#visualisierung-der-prozesskette","title":"Visualisierung der Prozesskette","text":""},{"location":"Fertigung/Fertigung/#fragestellung-eigene-maschine-oder-standardlosung","title":"Fragestellung: Eigene Maschine oder Standardl\u00f6sung?","text":"<p>Ein zentrales Thema ist die Frage, ob f\u00fcr diese Fertigungsschritte eine eigene Fertigungsmaschine entwickelt werden muss, oder ob sich bestehende L\u00f6sungen am Markt einsetzen bzw. kombinieren lassen.</p> <p>M\u00f6gliche Optionen:</p> <ul> <li>Standardmaschinen: CNC-Fr\u00e4sen, Plattens\u00e4gen, Bohrzentren, Lasermaschinen.  </li> <li>Kombinierte Bearbeitungszentren: Multifunktionale Maschinen f\u00fcr Zuschnitt, Bohren, Fr\u00e4sen und Gravieren.  </li> <li>Eigenentwicklung: Ma\u00dfgeschneiderte Maschine speziell f\u00fcr die Anforderungen der Balkonm\u00f6belproduktion.</li> </ul>"},{"location":"Fertigung/Fertigung/#nachster-schritt-maschinenvergleich","title":"N\u00e4chster Schritt: Maschinenvergleich","text":"<p>Im Dokument Maschinenvergleich sollen verschiedene Maschinen am Markt aufgelistet und gegen\u00fcbergestellt werden. Dazu wird eine Tabelle erstellt, die Funktionen, Kosten, Automatisierungsgrad und Integrationsm\u00f6glichkeiten vergleicht.</p>"},{"location":"Fertigung/Maschinenvergleich/","title":"Maschinenvergleich \u2013 Markt\u00fcbersicht","text":"<p>In diesem Dokument werden verschiedene Maschinen dargestellt, die potenziell zur vollautomatisierten Fertigung deiner Balkonm\u00f6bel geeignet sind. Die Tabelle vergleicht zentrale Merkmale und unterst\u00fctzt die Bewertung, ob eine Eigenentwicklung n\u00f6tig ist oder bestehende L\u00f6sungen eingesetzt werden k\u00f6nnen.</p> Hersteller Modell / Serie Funktionen / Merkmale Magazin / automatische Zuf\u00fchrung Automatisierungsgrad Eignet sich f\u00fcr \u201ejust-in-time\u201c Zuschnitt &amp; Bearbeitung? Hersteller-Link HOMAG CNC Bearbeitungszentren CNC f\u00fcr M\u00f6bel, Innenausbau, spezialisiert auf Vielseitigkeit ja (diverse Aufspanntische) sehr hoch Hervorragend f\u00fcr variantenreiche Produktion HOMAG Drillteq V-200 Intorex TC-1000 4-Achsen, Fr\u00e4sen, Bohrung, Schleifaggregat, mit Hopper-Zuf\u00fchrung (wsl. nicht f\u00fcr unterschiedliche L\u00e4ngen geeignet) ja (Hopper-Loader) mittel\u2013hoch Sehr spannend f\u00fcr automatisierten Workflow Intorex TC-1000 CATEKCNC CK-1530-ATC Multifunktionale CNC-Drehmaschine mit ATC (6-fach Magazin), 4-Achsen, Drehen, Fr\u00e4sen, Bohren, Nuten, Gravieren, Schleifen ja (Autom. Laden/Entladen + ATC) hoch Vielseitig, evtl. aber auf Drehteile optimiert CATEKCNC CK-1530-ATC"},{"location":"Fertigung/Maschinenvergleich/#zwischenfazit","title":"Zwischenfazit","text":"<p>Die bisher recherchierten Maschinen bieten viele n\u00fctzliche Funktionen f\u00fcr die Holzbearbeitung \u2013 insbesondere CNC-Zentren wie die von HOMAG oder multifunktionale Systeme wie die Intorex TC-1000 und die CATEKCNC CK-1530-ATC. Allerdings zeigt sich auch, dass keine der vorhandenen L\u00f6sungen den kompletten Anwendungsfall ideal abdeckt:</p> <ul> <li>Die meisten Maschinen sind f\u00fcr Serienfertigung oder Spezialbearbeitungen ausgelegt.  </li> <li>Systeme wie die Intorex TC-1000 oder CATEKCNC CK-1530-ATC sind spannend, jedoch prim\u00e4r f\u00fcr Drehteile bzw. standardisierte Werkst\u00fcckl\u00e4ngen konzipiert.  </li> <li>F\u00fcr eine hochflexible Produktion von individuell zugeschnittenen Brettern mit variablen L\u00e4ngen, Bohrungen, Fr\u00e4sungen und Lasergravuren gibt es aktuell keine vollst\u00e4ndig passende Standardl\u00f6sung.</li> </ul>"},{"location":"Fertigung/Maschinenvergleich/#ausblick","title":"Ausblick","text":"<p>Daher k\u00f6nnte es sinnvoll sein, \u00fcber die Entwicklung einer eigens konzipierten Fertigungsmaschine nachzudenken. Eine solche Maschine m\u00fcsste die folgenden Anforderungen abdecken:</p> <ul> <li>Automatischer Zuschnitt von Brettern auf variable L\u00e4nge.  </li> <li>Flexibles Bohren, Fr\u00e4sen und Gravieren in einem Arbeitsgang.  </li> <li>Automatische Materialzuf\u00fchrung und Sortierung f\u00fcr verschiedene Auftr\u00e4ge.  </li> <li>Softwareanbindung zur direkten \u00dcbernahme der Produktionslisten aus dem Online-Konfigurator.</li> </ul> <p>Eine eigene Entwicklung k\u00f6nnte die Effizienz steigern und gleichzeitig exakt auf die Anforderungen der individuellen Balkonm\u00f6belproduktion zugeschnitten sein. Allerdings erfordert dies eine detaillierte Machbarkeitsstudie sowie eine Kosten-Nutzen-Analyse, um den Vorteil gegen\u00fcber der Integration bestehender Systeme zu bewerten.</p>"},{"location":"Frontend/FloorplanConfigurator/","title":"Floorplan Editor","text":""},{"location":"Frontend/FloorplanConfigurator/#overview","title":"Overview","text":"<p>The Floorplan feature is an interactive, two-part tool that allows users to create a custom 2D room layout. It's designed to be simple and intuitive, starting users with a basic template and then providing a powerful editor to refine their shape.</p> <p>The entire system is built as a fully vector-based editor, ensuring that shapes can be scaled and manipulated with perfect precision, free from any pixelation.</p>"},{"location":"Frontend/FloorplanConfigurator/#user-workflow","title":"User Workflow","text":"<p>The user experience is broken into two distinct stages:</p> <ol> <li> <p>1. Shape Selection: The user is first presented with a grid of common room \"primitives\" or templates, such as a simple square, a rectangle, or an L-shaped room.</p> </li> <li> <p>2. Interactive Editing: After selecting a template, the user is taken into the Floorplan Workspace. This is an infinite canvas where they can pan, zoom, and directly manipulate the shape to match their exact specifications.</p> </li> </ol> <p>Once finished, the user can save their design, which finalizes the shape's vertex data.</p>"},{"location":"Frontend/FloorplanConfigurator/#key-features-capabilities","title":"Key Features &amp; Capabilities","text":"<p>The workspace provides a rich set of editing tools:</p> <ul> <li> <p>View Navigation:</p> <ul> <li>Pan: Users can click and drag the grid background to pan the viewport.</li> <li>Zoom: Using the mouse wheel, users can zoom in and out, with the zoom centered on the cursor for intuitive control.</li> </ul> </li> <li> <p>Shape Manipulation:</p> <ul> <li>Move Vertices: Users can grab any corner (vertex) of the shape and drag it.</li> <li>Move Edges: Users can grab any wall (edge) and move it, which repositions the two connected vertices along that wall's normal.</li> <li>Add Vertices: By clicking and dragging a special handle at the midpoint of any wall, users can \"pull out\" a new corner, splitting one wall into two.</li> </ul> </li> <li> <p>Precision and Alignment:</p> <ul> <li>Precise Length Input: The length of each wall is displayed as a text label. Users can click this label to type in an exact numerical length for that wall.</li> <li>Grid Snapping: All drag operations (for vertices, edges, or new points) automatically snap to a background grid, ensuring clean lines and easy alignment.</li> </ul> </li> </ul>"},{"location":"Frontend/FloorplanConfigurator/#technical-implementation-highlights","title":"Technical Implementation Highlights","text":"<p>Instead of being a pixel-based (raster) editor like MS Paint, the floorplan tool is a vector graphics editor built using SVG (Scalable Vector Graphics).</p> <ul> <li> <p>Vector-Based by Design: The room's shape is not stored as pixels. It's stored in React state as a simple array of vertices (e.g., <code>[{x: 10, y: 10}, {x: 100, y: 10}, ...]</code>). The SVG <code>&lt;polygon&gt;</code> element renders this data visually.</p> </li> <li> <p>Benefits of SVG:</p> <ul> <li>Infinite Scalability: The shape, grid, and handles can be zoomed in on indefinitely without any loss of quality or pixelation.</li> <li>Object-Based Interaction: Every part of the shape (the main polygon, the circular vertex handles, the edge midpoint handles) is its own SVG element. This makes it simple to attach specific event listeners (like <code>onMouseDown</code>) to each part.</li> </ul> </li> <li> <p>State-Driven Rendering: All interactions are handled by React. When a user drags a vertex, they are simply updating the <code>points</code> array in the component's state. React then re-renders the SVG with the new vertex coordinates, making the editing feel instantaneous.</p> </li> <li> <p>Coordinate Space Transformation: A key piece of the logic is the set of helper functions that translate coordinates. When a user clicks, the editor must translate that screen-space (pixel) coordinate into the local-space (vector) coordinate of the shape, accounting for the current pan and zoom level. This allows a user's mouse movement to be correctly applied to the shape's data.</p> </li> </ul>"},{"location":"Frontend/Framework/","title":"Framework: Why We Use React as a framework","text":"<p>This document provides a high-level overview of why React was chosen as the framework for this application and how its core principles are used to manage our interactive tools.</p>"},{"location":"Frontend/Framework/#why-react","title":"Why React?","text":"<p>React is a JavaScript library for building user interfaces. It's particularly well-suited for our project, which involves managing complex, interactive state for both a 2D editor and a 3D configurator.</p> <ul> <li> <p>Component-Based Architecture: Our entire application is built from small, independent, and reusable \"components.\"</p> <ul> <li>The <code>Floorplan</code> selector is a component.</li> <li>The <code>FloorplanWorkspace</code> editor is another component.</li> <li>The <code>Configurator</code> 3D scene is a component.</li> <li>Even the UI sliders and buttons are individual components.     This makes the code easy to manage, test, and update without one part breaking another.</li> </ul> </li> <li> <p>Declarative UI (State Management): This is the most important concept.</p> <ul> <li>Traditional (Imperative): In older code, you'd write step-by-step instructions like: \"find the slider,\" \"get its value,\" \"find the 3D model,\" \"update the model's X position.\" This is complex and error-prone.</li> <li>React (Declarative): We simply declare the state we want. We have a state variable, <code>modelPositionX</code>. The slider's value is bound to this state, and the 3D model's position is derived from this state. When the user moves the slider, it updates the state, and React automatically ensures the 3D model's position updates to match. We just describe the \"what\" (the model's position should match this variable), and React handles the \"how.\"</li> </ul> </li> <li> <p>Rich Ecosystem: React is the most popular UI library, meaning it has a massive community and integrates well with other libraries. This is crucial for us, as it simplifies the integration of powerful tools like <code>three.js</code> (for 3D graphics) and <code>react-router-dom</code> (for navigation).</p> </li> </ul>"},{"location":"Frontend/Framework/#how-it-all-works-together-data-flow","title":"How It All Works Together: Data Flow","text":"<p>React uses a one-way data flow, which makes the application predictable. Data flows \"down\" from parent components to children, and events (like user clicks) flow \"up\" via callback functions.</p> <p>Here is a simplified diagram of our application's architecture:</p> <pre><code>[ App.js ]  &lt;---------------------------------------+\n   |                                                | 4. `onFinish` callback updates the\n   | (State: floorplanPoints)                       |    `floorplanPoints` state.\n   |                                                |\n   +--&gt; [ Floorplan.js ] --- (passes onFinish) ----&gt; [ FloorplanWorkspace.js ]\n   |      (Renders workspace)                         |\n   |                                                  | 3. User clicks \"Finish,\"\n   |                                                  |    and workspace calls `onFinish(points)`.\n   |                                                  |\n   +--&gt; [ Configurator.js ] &lt;------------------------+\n        (Receives floorplanPoints as a \"prop\")        |\n                                                      | 5. React sees state changed\n                                                      |    and re-renders Configurator\n                                                      |    with the *new* points.\n</code></pre>"},{"location":"Frontend/Framework/#the-step-by-step-flow","title":"The Step-by-Step Flow","text":"<ol> <li> <p>Top-Level State: The main <code>App</code> component holds the most important piece of state: <code>floorplanPoints</code>.</p> </li> <li> <p>Data Down (Props):</p> <ul> <li>The <code>App</code> component renders the <code>Floorplan</code> component, passing it a function prop called <code>onFinish</code>.</li> <li>The <code>App</code> component also renders the <code>Configurator</code> component, passing it the current <code>floorplanPoints</code> array as a prop.</li> </ul> </li> <li> <p>Events Up (Callbacks):</p> <ul> <li>When the user finishes drawing in the <code>FloorplanWorkspace</code>, they click the \"Finish\" button.</li> <li>The workspace calls the <code>onFinish</code> function it received, passing the new array of points (e.g., <code>onFinish([...])</code>).</li> </ul> </li> <li> <p>State Update:</p> <ul> <li>This <code>onFinish</code> function lives in the main <code>App</code> component. When called, it updates the <code>floorplanPoints</code> state inside <code>App</code> with the new points.</li> </ul> </li> <li> <p>Automatic Re-render:</p> <ul> <li>React detects that the <code>floorplanPoints</code> state has changed.</li> <li>It automatically re-renders any component that depends on that state. In this case, it re-renders the <code>Configurator</code> component.</li> <li>The <code>Configurator</code> now receives the new <code>floorplanPoints</code> as its prop, triggering its internal <code>useEffect</code> hook to discard the old 3D floor and generate a new one.</li> </ul> </li> </ol>"},{"location":"Frontend/Framework/#the-bridge-to-threejs-useeffect","title":"The Bridge to <code>three.js</code>: <code>useEffect</code>","text":"<p>React manages the DOM, but <code>three.js</code> manages a <code>&lt;canvas&gt;</code> element. We use the <code>useEffect</code> hook as the bridge between these two worlds.</p> <p>In the <code>Configurator</code> component, the <code>useEffect</code> hook essentially says: \"When the <code>floorplanPoints</code> prop changes, run this code to build (or re-build) the <code>three.js</code> scene.\"</p> <p>This hook is also responsible for cleanup. When the component is removed, the <code>useEffect</code>'s return function runs, which safely disposes of all <code>three.js</code> geometries, materials, and the renderer. This prevents memory leaks and is a critical part of mixing React with external libraries.</p>"},{"location":"Frontend/Manifold/Model-Development-Guide/","title":"NatureForm Model Plugin Guide","text":"<p>This guide explains how to create and structure a 3D model file so that it is automatically compatible with the NatureForm Playground. Our architecture uses a decoupled plugin system, meaning each model is self-contained and manages its own parameters, geometry logic, and rendering style.</p>"},{"location":"Frontend/Manifold/Model-Development-Guide/#1-file-location","title":"1. File Location","text":"<p>All model files must be placed in: <code>src/utils/Objects/[YourModelName].js</code></p>"},{"location":"Frontend/Manifold/Model-Development-Guide/#2-required-structure","title":"2. Required Structure","text":"<p>Every model file must export exactly three items: 1. <code>config</code>: Defines the UI sliders and inputs. 2. <code>generator</code>: Handles the heavy math and Manifold (Boolean) operations. 3. <code>render</code>: Bridges the Manifold data to Three.js meshes and materials.</p>"},{"location":"Frontend/Manifold/Model-Development-Guide/#3-detailed-export-requirements","title":"3. Detailed Export Requirements","text":""},{"location":"Frontend/Manifold/Model-Development-Guide/#a-the-config-object","title":"A. The <code>config</code> Object","text":"<p>The config object tells the GUI (lil-gui) which sliders and folders to create.</p> <pre><code>export const config = {\n  type: 'My Unique Model Name', // Used as the ID in the dropdown\n  label: 'User Friendly Label', \n  params: [\n    { \n      name: 'width', \n      type: 'number', \n      default: 1000, \n      min: 100, \n      max: 5000, \n      label: 'Overall Width', \n      folder: 'Dimensions' \n    },\n    { \n      name: 'materialType', \n      type: 'select', \n      options: ['Wood', 'Metal'], \n      default: 'Wood', \n      folder: 'Visuals' \n    }\n  ]\n};\n</code></pre>"},{"location":"Frontend/Manifold/Model-Development-Guide/#b-the-generator-function","title":"B. The generator Function","text":"<p>This function should perform the geometry calculations. It must return an object containing named Manifold parts.</p> <p>Input: manifoldLib (The WASM library) and inputParams (Current slider values).</p> <p>Output: An object where keys are part names (e.g., { seat: manifoldObj, legs: manifoldObj }).</p> <pre><code>export function generator(manifoldLib, inputParams) {\n  const { Manifold } = manifoldLib;\n  const { cube } = Manifold;\n\n  // Logic here\n  const myCube = cube([inputParams.width, 400, 450]);\n\n  return {\n    mainPart: myCube\n  };\n}\n</code></pre>"},{"location":"Frontend/Manifold/Model-Development-Guide/#c-the-render-function","title":"C. The render Function","text":"<p>The render function is called by the Playground to turn Manifold geometry into visible Three.js objects.</p> <ul> <li> <p>result: The object returned by your generator.</p> </li> <li> <p>group: The Three.js Group where you should add your meshes.</p> </li> <li> <p>helpers: An API provided by the Playground containing:</p> </li> <li> <p>createThreeMesh: Function to convert Manifold to Three.js Mesh.</p> </li> <li> <p>applyBoxUV: Standardized UV mapping.</p> </li> <li> <p>textureLoader: For loading local images.</p> </li> <li> <p>THREE: Access to the Three.js constant library.</p> </li> </ul> <pre><code>export function render(result, group, helpers, appState) {\n  const { createThreeMesh, applyBoxUV, textureLoader, THREE } = helpers;\n\n  // 1. Create Materials (and load textures)\n  const mat = new THREE.MeshStandardMaterial({ color: 0x888888 });\n\n  // 2. Convert and Add to scene\n  if (result.mainPart) {\n    const mesh = createThreeMesh(result.mainPart, mat);\n    applyBoxUV(mesh.geometry, 0.0005); // Standard scale\n    group.add(mesh);\n  }\n}\n</code></pre>"},{"location":"Frontend/Manifold/Model-Development-Guide/#4-best-practices","title":"4. Best Practices","text":"<p>Self-Contained Textures To keep the Playground clean, import your textures directly at the top of your model file. This ensures that when you move the file, the textures move with it.</p> <pre><code>import diffUrl from '../../assets/my_textures/diffuse.jpg';\n</code></pre>"},{"location":"Frontend/Manifold/Model-Development-Guide/#performance","title":"Performance","text":"<p>Boolean operations are expensive.</p> <p>Try to keep the number of Manifold operations (subtract, union) to a minimum.</p> <p>In the render function, always check if a part exists (if (result.partName)) before creating a mesh.</p> <p>Dispose of old geometries? No need\u2014the Playground handles the cleanup of the modelGroup automatically before every regeneration.</p> <p>Shaders and Grooves If your model requires custom logic (like the procedural wood grooves), implement the onBeforeCompile logic inside your render function. This keeps specialized shader code isolated to the specific model that needs it.</p>"},{"location":"Frontend/Manifold/Model-Development-Guide/#troubleshooting","title":"Troubleshooting","text":"<p>Model not showing up? Check the Browser Console (F12). The Playground logs a warning if a file is missing one of the three required exports (config, generator, render).</p> <p>UI not updating? Ensure your config.params names match the keys you are accessing in the generator via inputParams.</p>"},{"location":"Frontend/ModelConfigurator/","title":"Model Configurator","text":"<p>This document describes the <code>Configurator</code> component, which serves as the primary \"glue\" for the 3D model interaction scene. It is a stateful React component (part of the overall framework) that mounts and manages a <code>three.js</code> environment (see Three.js setup).</p> <p>This component is responsible for:</p> <ul> <li>Initializing the 3D renderer, scene, camera, and lighting.</li> <li>Loading and displaying the floor, either as a default rectangle or a custom shape from the Floorplan Configurator.</li> <li>Instantiating and managing the procedural <code>WrappedCrate</code> model.</li> <li>Handling all user interactions from the <code>ConfiguratorSidebar</code>.</li> <li>Running all collision detection logic to ensure the model stays within the floor bounds.</li> </ul>"},{"location":"Frontend/ModelConfigurator/#core-concepts","title":"Core Concepts","text":"<p>The <code>Configurator</code> works by blending React's state and component lifecycle with the imperative <code>three.js</code> library.</p>"},{"location":"Frontend/ModelConfigurator/#1-react-threejs-integration","title":"1. React + Three.js Integration","text":"<ul> <li><code>useRef</code> for 3D Objects: All <code>three.js</code> objects that need to be persisted (like the <code>scene</code>, <code>renderer</code>, <code>modelRef</code>, <code>floorRef</code>, etc.) are stored in React <code>useRef</code> hooks. This gives us a stable reference that doesn't trigger re-renders.</li> <li><code>useState</code> for UI Controls: All values controlled by the UI (like <code>modelPosition</code>, <code>modelRotation</code>, <code>cratePlanks</code>) are stored in React <code>useState</code> hooks.</li> <li><code>useEffect</code> for Setup/Cleanup: A single, large <code>useEffect</code> hook initializes the entire <code>three.js</code> scene on mount. The <code>return</code> function from this hook is critical for cleanup, as it properly disposes of all <code>three.js</code> objects to prevent memory leaks.</li> </ul>"},{"location":"Frontend/ModelConfigurator/#2-dynamic-floor-generation","title":"2. Dynamic Floor Generation","text":"<p>The component has two modes for generating the floor based on the <code>floorplanPoints</code> prop:</p> <ul> <li>Default Mode (Rectangular): If <code>floorplanPoints</code> is empty, it creates a simple <code>THREE.PlaneGeometry</code> and a matching 4-point collision polygon.</li> <li>Custom Mode (From Floorplan): If <code>floorplanPoints</code> is provided (from the Floorplan Configurator), it creates a <code>THREE.ShapeGeometry</code> from the points. It also generates a precise 2D collision polygon (<code>floorPolygonRef.current</code>) from these points, which is then used by the collision system.</li> </ul>"},{"location":"Frontend/ModelConfigurator/#3-procedural-model-footprint","title":"3. Procedural Model &amp; Footprint","text":"<p>The main model is a live instance of the <code>WrappedCrate</code> class, as documented in WrappingLogic.md.</p> <ul> <li>Model: <code>modelRef.current</code> is the <code>WrappedCrate</code> instance. Its size is controlled by calling <code>modelRef.current.setSize(newSize)</code>.</li> <li>Footprint: <code>footprintRef.current</code> is a simple <code>THREE.PlaneGeometry</code> that is created as a child of the model.<ul> <li>Its dimensions are calculated to match the crate's \"snapped\" size.</li> <li>Because it's a child, it automatically inherits the model's position and rotation.</li> <li>This mesh is passed directly to the collision functions.</li> </ul> </li> </ul> <p>Note: The footprint used here is a simple <code>PlaneGeometry</code> for performance. For a more advanced method of generating a footprint from a dynamic model, see the Silhouette Extraction process.</p>"},{"location":"Frontend/ModelConfigurator/#4-advanced-collision-interaction-logic","title":"4. Advanced Collision &amp; Interaction Logic","text":"<p>The component's main feature is its \"smart\" handlers that prevent invalid user states.</p> <ol> <li>The Check: All handlers use the <code>checkCollision()</code> function, which in turn calls <code>isSilhouetteInsideFloorspace</code> from the Collision Logic.</li> <li>Position Handling (Bisection): When a user drags a position slider, if an invalid position is detected, it performs a binary search between the last good position and the new invalid one. This allows the model to slide smoothly along walls.</li> <li>Rotation Handling (Nudging): When a user rotates the model, if a collision occurs, the component tries to \"nudge\" the model towards the floor's center. If it finds a valid spot, it accepts both the rotation and the new nudged position.</li> <li>Resize Handling (Pushing): When a user resizes the crate, if the new size causes a collision, the component attempts to \"push\" the model away from the growing side (e.g., push on the +X axis if <code>numPlanksX</code> increases). If this push is valid, the resize is accepted. If not, it's reverted.</li> </ol>"},{"location":"Frontend/ModelConfigurator/#key-functions-handlers","title":"Key Functions &amp; Handlers","text":""},{"location":"Frontend/ModelConfigurator/#checkcollision","title":"<code>checkCollision()</code>","text":"<ul> <li>Type: <code>useCallback</code></li> <li>Purpose: The central collision-checking function.</li> <li>Logic:<ol> <li>Gets the <code>footprintRef</code> (the model's silhouette mesh) and <code>floorPolygonRef</code> (the 2D floor polygon).</li> <li>Calls <code>isSilhouetteInsideFloorspace(footprint, floorPolygon)</code>.</li> <li>Updates the <code>footprintRef</code> material's color to green (valid) or red (invalid).</li> <li>Returns <code>true</code> or <code>false</code>.</li> </ol> </li> </ul>"},{"location":"Frontend/ModelConfigurator/#handlepositionxchangevalue-handlepositionzchangevalue","title":"<code>handlePositionXChange(value)</code> / <code>handlePositionZChange(value)</code>","text":"<ul> <li>Type: <code>useCallback</code></li> <li>Purpose: Handles user input for changing the model's X or Z position.</li> <li>Logic: Performs the \"Bisection\" logic described above to find the closest valid position to the wall.</li> </ul>"},{"location":"Frontend/ModelConfigurator/#handlerotationychangevalue","title":"<code>handleRotationYChange(value)</code>","text":"<ul> <li>Type: <code>useCallback</code></li> <li>Purpose: Handles user input for changing the model's Y-axis rotation.</li> <li>Logic: Performs the \"Nudging\" logic described above to find a valid position after rotating.</li> </ul>"},{"location":"Frontend/ModelConfigurator/#handleplankchangeaxis-value","title":"<code>handlePlankChange(axis, value)</code>","text":"<ul> <li>Type: <code>useCallback</code></li> <li>Purpose: Handles user input for resizing the crate.</li> <li>Logic: Performs the \"Pushing\" logic described above to validate a resize. Also re-builds the <code>footprintRef.current.geometry</code> to match the new crate size.</li> </ul>"},{"location":"Frontend/ModelConfigurator/Collision/","title":"2D Floorplan Collision &amp; Utilities","text":"<p>This document outlines the utility functions used for 2D collision and containment checks. The primary goal of this code is to determine if a 3D object's 2D footprint (its \"silhouette\") is fully contained within a 2D floorplan polygon.</p> <p>This functionality is essential for interactive configurators to validate object placement, preventing users from moving items outside a defined room, placing objects on top of each other, or having them intersect with walls.</p>"},{"location":"Frontend/ModelConfigurator/Collision/#core-logic-issilhouetteinsidefloorspace","title":"Core Logic: <code>isSilhouetteInsideFloorspace</code>","text":"<p>The main function, <code>isSilhouetteInsideFloorspace</code>, performs a robust, two-part check to confirm an object is fully contained within the floorplan.</p> <p>For an object to be considered \"inside,\" both of the following conditions must be true:</p> <ol> <li>All Points Inside: Every single vertex of the object's 2D silhouette must be inside the floorplan polygon. This check is performed by the <code>isPointInPolygon</code> helper.</li> <li>No Edges Intersect: No edge (the line between two vertices) of the silhouette can cross any edge of the floorplan polygon. This check is performed by the <code>doLinesIntersect</code> helper.</li> </ol> <p>This dual-check system is crucial. It correctly handles complex cases, such as a large \"U\" shaped object attempting to wrap around a small part of the floorplan, which might have its vertices inside but its edges intersecting.</p>"},{"location":"Frontend/ModelConfigurator/Collision/#function-reference","title":"Function Reference","text":""},{"location":"Frontend/ModelConfigurator/Collision/#issilhouetteinsidefloorspacesilhouettemesh-floorpolygon","title":"<code>isSilhouetteInsideFloorspace(silhouetteMesh, floorPolygon)</code>","text":"<ul> <li>Purpose: The primary function. Checks if a given silhouette mesh is fully contained within a floorplan polygon.</li> <li>Parameters:<ul> <li><code>silhouetteMesh</code>: The <code>THREE.Mesh</code> representing the object's 2D footprint.</li> <li><code>floorPolygon</code>: An array of 2D points (e.g., <code>{x: 10, y: 5}</code>) defining the floor's boundary.</li> </ul> </li> <li>Returns: <code>true</code> if the silhouette is fully inside, <code>false</code> otherwise.</li> </ul>"},{"location":"Frontend/ModelConfigurator/Collision/#gettransformedsilhouetteverticessilhouettemesh","title":"<code>getTransformedSilhouetteVertices(silhouetteMesh)</code>","text":"<ul> <li>Purpose: Extracts a 2D vertex list (a polygon) from a 3D silhouette mesh.</li> <li>Process:<ol> <li>Ensures the mesh's world matrix is up-to-date.</li> <li>Reads the vertex <code>position</code> data from the mesh's geometry.</li> <li>Applies the mesh's <code>matrixWorld</code> (its final world position, rotation, and scale) to every vertex.</li> <li>Converts the 3D <code>(x, y, z)</code> coordinates into 2D <code>(x, y)</code> coordinates by using the <code>x</code> and <code>z</code> values (the top-down footprint).</li> <li>De-duplicates the vertices to create a clean polygon.</li> </ol> </li> <li>Returns: An array of unique 2D points (e.g., <code>[{x: 1, y: 1}, {x: 2, y: 1}, ...]</code>).</li> </ul>"},{"location":"Frontend/ModelConfigurator/Collision/#dolinesintersectp1-p2-p3-p4","title":"<code>doLinesIntersect(p1, p2, p3, p4)</code>","text":"<ul> <li>Purpose: A mathematical helper to check if two 2D line segments, (p1, p2) and (p3, p4), intersect.</li> <li>Algorithm: Uses a standard computational geometry algorithm based on the orientation (clockwise, counter-clockwise, or collinear) of the three-point combinations.</li> <li>Returns: <code>true</code> if the segments cross, <code>false</code> otherwise.</li> </ul>"},{"location":"Frontend/ModelConfigurator/Collision/#ispointinpolygonpoint-polygon","title":"<code>isPointInPolygon(point, polygon)</code>","text":"<ul> <li>Purpose: A mathematical helper to check if a 2D point is inside a 2D polygon.</li> <li>Algorithm: Implements the Ray-Casting Algorithm. It \"casts\" an imaginary ray from the point in one direction (e.g., positive X) and counts how many times it crosses the polygon's edges.<ul> <li>An odd number of crossings means the point is inside.</li> <li>An even number of crossings means the point is outside.</li> </ul> </li> <li>Returns: <code>true</code> if the point is inside, <code>false</code> otherwise.</li> </ul>"},{"location":"Frontend/ModelConfigurator/SilhouetteExtractor/","title":"Extracting a 2D Silhouette (Deprecated)","text":"<p>This document outlines the process for dynamically generating a 2D silhouette polygon from a 3D model. This technique is highly effective for creating accurate 2D physics colliders for 3D objects, especially in a top-down perspective, as it accounts for the model's current shape (e.g., from an animation).</p>"},{"location":"Frontend/ModelConfigurator/SilhouetteExtractor/#the-process","title":"The Process","text":"<p>The workflow involves rendering the object's shape to a texture and then using image processing algorithms to convert that 2D image into a 2D physics-ready polygon.</p>"},{"location":"Frontend/ModelConfigurator/SilhouetteExtractor/#1-optimize-model-optional","title":"1. Optimize Model (Optional)","text":"<p>To improve the performance of the render-to-texture step, it's beneficial to use a lower-polygon version of your model. This step can often be skipped if the source model is already reasonably low-poly.</p>"},{"location":"Frontend/ModelConfigurator/SilhouetteExtractor/#2-setup-top-down-orthographic-camera","title":"2. Setup Top-Down Orthographic Camera","text":"<p>Position an orthographic camera directly above the model, looking straight down. This camera will be used to capture the 2D \"shadow\" or outline of the object on the X/Z plane.</p>"},{"location":"Frontend/ModelConfigurator/SilhouetteExtractor/#3-render-to-texture","title":"3. Render-to-Texture","text":"<p>Render the 3D object (using its dynamic, possibly animated, shape) into a separate, low-resolution off-screen buffer, also known as a render target.</p> <p>This render must use a simple, unlit shader that renders the object as pure white against a pure black background. The resulting texture is a binary (black and white) 2D representation of the model's silhouette.</p>"},{"location":"Frontend/ModelConfigurator/SilhouetteExtractor/#4-read-pixels","title":"4. Read Pixels","text":"<p>Read the pixel data from the render target texture back to the CPU. This gives you a 2D grid of binary data (1s for white, 0s for black) that represents the object's shape.</p>"},{"location":"Frontend/ModelConfigurator/SilhouetteExtractor/#5-trace-outline","title":"5. Trace Outline","text":"<p>Process this 2D pixel grid using an outline-tracing algorithm like Marching Squares. This algorithm \"walks\" the boundary between the white (object) and black (empty) pixels, generating a 2D polygon (a list of 2D vertices) that describes the outline of the \"blob.\"</p>"},{"location":"Frontend/ModelConfigurator/SilhouetteExtractor/#6-simplify-polygon-optional","title":"6. Simplify Polygon (Optional)","text":"<p>The polygon generated by Marching Squares will be very detailed and \"jagged,\" as it follows the pixel edges perfectly. This high vertex count can be inefficient for a physics engine.</p> <p>If needed, use a polygon simplification algorithm (such as Ramer-Douglas-Peucker) to reduce the vertex count significantly while preserving the overall shape. This step may not be necessary if the render-to-texture resolution is very low, as the resulting polygon will already be quite simple.</p>"},{"location":"Frontend/ModelConfigurator/SilhouetteExtractor/#7-decompose-polygon-if-needed","title":"7. Decompose Polygon (If Needed)","text":"<p>Most 2D physics engines require collision shapes to be convex (i.e., no \"dents\" or \"caves\"). If the silhouette shape is concave (e.g., a \"U\" shape), it must be broken down into a set of smaller, convex polygons. This is achieved by running the polygon's vertices through a 2D convex decomposition algorithm.</p>"},{"location":"Frontend/ModelConfigurator/SilhouetteExtractor/#8-normalize-coordinates","title":"8. Normalize Coordinates","text":"<p>The final step is to convert the polygon's vertices from their pixel coordinates (e.g., 0-256) back into the 2D world-space or local-space coordinates that the physics engine understands (e.g., mapping the pixel positions back to the model's X and Z coordinates).</p>"},{"location":"Frontend/ModelConfigurator/SilhouetteExtractor/#final-output","title":"Final Output","text":"<p>The result of this process is a set of one or more 2D convex polygons that accurately represent the top-down silhouette of the 3D model, ready to be used by a 2D physics engine.</p>"},{"location":"Frontend/ModelConfigurator/WrappingLogic/","title":"Procedural Crate Generation","text":"<p>This document outlines the logic for the <code>WrappedCrate</code> class, a dynamic and performant 3D object used to represent a crate or pallet built from individual planks.</p> <p>The class is designed for scenarios where a crate needs to be procedurally resized (e.g., by a user in a configurator) while maintaining a realistic appearance. It achieves high performance by using <code>THREE.InstancedMesh</code> to draw all planks in a single draw call, rather than creating hundreds of individual <code>THREE.Mesh</code> objects.</p>"},{"location":"Frontend/ModelConfigurator/WrappingLogic/#core-logic-snapping-and-rebuilding","title":"Core Logic: Snapping and Rebuilding","text":"<p>The most important concept in this class is the \"snapping\" logic. A user might request an arbitrary size (e.g., 1.23m), but the crate can only be built from discrete plank widths (e.g., 0.1m).</p> <p>The <code>setSize</code> method handles this automatically.</p> <ol> <li>Snapping: When <code>setSize(requestedSize)</code> is called, it doesn't immediately use that size. Instead, it calculates the nearest valid \"snapped\" size that can be built using the given <code>plankWidth</code> and <code>gapSize</code>.</li> <li>Optimization: The class stores its current snapped size. It compares the new snapped size to the old one. If they are the same (e.g., the user is dragging their mouse but hasn't moved far enough to add/remove a plank), the function does nothing.</li> <li>Rebuild: If the new snapped size is different, it triggers the internal <code>rebuild()</code> method. This function recalculates the position and scale for every single plank needed to build the 6 faces of the crate.</li> <li>Instancing: The <code>rebuild()</code> method populates the <code>InstancedMesh</code> with the matrix data (position, rotation, scale) for every plank. Finally, it updates the <code>InstancedMesh</code>'s <code>count</code> to render the new set of planks.</li> </ol> <p>This entire process ensures that the crate always looks correct for its parts, and it prevents costly, high-frequency rebuilds while a user is actively resizing the object.</p>"},{"location":"Frontend/ModelConfigurator/WrappingLogic/#class-reference","title":"Class Reference","text":""},{"location":"Frontend/ModelConfigurator/WrappingLogic/#wrappedcrate","title":"<code>WrappedCrate</code>","text":"<p>This class extends <code>THREE.Group</code> and manages the <code>InstancedMesh</code> for all planks.</p>"},{"location":"Frontend/ModelConfigurator/WrappingLogic/#constructorinitialsize-plankwidth-plankthickness-material-maxplanks","title":"<code>constructor(initialSize, plankWidth, plankThickness, material, maxPlanks)</code>","text":"<ul> <li>Purpose: Creates a new <code>WrappedCrate</code> instance.</li> <li>Parameters:<ul> <li><code>initialSize</code>: <code>THREE.Vector3</code> - The starting dimensions of the crate.</li> <li><code>plankWidth</code>: <code>number</code> - The width of each individual plank.</li> <li><code>plankThickness</code>: <code>number</code> - The thickness (height) of each plank.</li> <li><code>material</code>: <code>THREE.Material</code> - The material to be shared by all plank instances.</li> <li><code>maxPlanks</code> (Optional): <code>number</code> - The maximum number of planks to pre-allocate memory for. Defaults to <code>5000</code>.</li> </ul> </li> </ul>"},{"location":"Frontend/ModelConfigurator/WrappingLogic/#setsizerequestedsize","title":"<code>.setSize(requestedSize)</code>","text":"<ul> <li>Purpose: The main public method for updating the crate's dimensions.</li> <li>Parameters:<ul> <li><code>requestedSize</code>: <code>THREE.Vector3</code> - The desired target size for the crate.</li> </ul> </li> <li>Behavior: This method triggers the \"Snapping and Rebuilding\" logic. The crate's visual size will snap to the nearest valid dimension based on the <code>plankWidth</code>, and the geometry will only be rebuilt if this snapped size changes.</li> </ul>"},{"location":"Frontend/ThreeJS/","title":"Framework: Why We Use Three.js","text":"<p>This document covers why Three.js was chosen as our 3D rendering library and the basic concepts of how it powers our <code>Configurator</code> component.</p>"},{"location":"Frontend/ThreeJS/#why-threejs","title":"Why Three.js?","text":"<p>Three.js is a 3D graphics library that renders complex 3D scenes in a web browser using WebGL. It's the engine that draws everything inside our <code>Configurator</code>'s <code>&lt;canvas&gt;</code> element.</p> <ul> <li> <p>It's an Abstraction, Not a Game Engine:     We don't need a heavy, all-in-one platform like Unity or Unreal Engine. We just need a powerful library that can draw 3D objects inside our existing React application. Three.js is the perfect fit. It gives us low-level control without forcing us to write raw, complex WebGL code.</p> </li> <li> <p>It's Just JavaScript:     There are no plugins or external software. It's a JavaScript library that integrates directly into our React component. This allows us to pass data (like the <code>floorplanPoints</code>) from our 2D React components straight into the 3D scene.</p> </li> <li> <p>Performance:     It's a very thin layer over WebGL, which means it runs directly on the computer's GPU. This allows us to render complex models, lighting, and shadows at a high frame rate (60fps).</p> </li> <li> <p>Vast Ecosystem &amp; Community:     Three.js is the most popular 3D library for the web. This means it has an enormous community and a vast collection of \"helpers\" and utilities. We use several of these:</p> <ul> <li><code>GLTFLoader</code>: To load our 3D sofa model.</li> <li><code>OrbitControls</code>: To provide the \"click and drag\" camera controls out of the box.</li> <li><code>BufferGeometryUtils</code>: To merge our dynamic \"footprint\" geometry into a single, efficient mesh.</li> </ul> </li> </ul>"},{"location":"Frontend/ThreeJS/#how-it-works-the-core-concepts","title":"How It Works: The Core Concepts","text":"<p>Think of a Three.js application as a movie set. To film anything, you need three basic things:</p> <ol> <li> <p>A <code>Scene</code>: This is the stage or the virtual world. It's an empty container where you place all your objects, models, and lights.</p> </li> <li> <p>A <code>Camera</code>: This is the \"eye\" that looks at the scene. We use a <code>PerspectiveCamera</code>, which mimics a real-world camera (objects farther away appear smaller).</p> <ul> <li>(Note: Our <code>SilhouetteExtractor</code> utility uses an <code>OrthographicCamera</code>, which is a \"flat\" camera with no perspective, like a 2D blueprint.)</li> </ul> </li> <li> <p>A <code>Renderer</code>: This is the \"artist\" and crew. It takes the <code>Scene</code> and the <code>Camera</code>, calculates what the scene looks like from the camera's point of view, and draws the final 2D image onto the HTML <code>&lt;canvas&gt;</code> element. This \"drawing\" happens in a loop (using <code>requestAnimationFrame</code>) 60 times per second.</p> </li> </ol>"},{"location":"Frontend/ThreeJS/#whats-in-our-scene","title":"What's in Our Scene?","text":"<p>Our scene is filled with a few key types of objects:</p> <ul> <li> <p>Meshes: A <code>Mesh</code> is the main 3D object you see. Every <code>Mesh</code> is a combination of two things:</p> <ol> <li>Geometry: The shape or 3D data (the vertices and faces).<ul> <li>This can be a primitive (like <code>BoxGeometry</code>).</li> <li>It can be a loaded model (like our sofa).</li> <li>It can be custom-generated (like our <code>ShapeGeometry</code>, which we create from the user's <code>floorplanPoints</code>!).</li> </ul> </li> <li>Material: The skin or surface (the color, texture, and shininess).<ul> <li>We use <code>MeshStandardMaterial</code> for the floor and sofa because it's a realistic material that reacts to light.</li> <li>We use <code>MeshBasicMaterial</code> for the green \"footprint,\" as it's a simple, flat color that is not affected by lights.</li> </ul> </li> </ol> </li> <li> <p>Lights: Without lights, most materials would appear black.</p> <ul> <li><code>AmbientLight</code>: Provides a soft, general light to the whole scene so nothing is in pure black shadow.</li> <li><code>DirectionalLight</code>: Acts like the \"sun.\" It shines from one direction and is the source that allows our sofa to cast realistic shadows onto the floor.</li> </ul> </li> </ul>"},{"location":"Frontend/ThreeJS/#how-it-fits-in-our-react-app","title":"How It Fits in Our React App","text":"<p>We don't use Three.js by itself; we wrap it entirely within our <code>Configurator</code> React component.</p> <ul> <li> <p>The <code>useEffect</code> Hook is the Bridge:     Our <code>Configurator</code> has a <code>useEffect</code> hook that runs when the component first appears. This hook is where we call our <code>init()</code> function to:</p> <ol> <li>Create the <code>Scene</code>, <code>Camera</code>, and <code>Renderer</code>.</li> <li>Create the <code>&lt;canvas&gt;</code> element and append it to the DOM.</li> <li>Load the 3D model, create the lights, and start the <code>animate</code> loop.</li> </ol> </li> <li> <p>State &amp; Props as Triggers:     The <code>useEffect</code> hook is set to \"watch\" the <code>floorplanPoints</code> prop. If the user goes back and changes their floorplan, the <code>floorplanPoints</code> prop changes, and React re-runs the hook. This triggers our logic to throw away the old 3D floor and generate a new one from the new points.</p> </li> <li> <p>Cleanup is Essential:     The <code>return</code> function inside the <code>useEffect</code> hook is our cleanup crew. When the user navigates away from the <code>Configurator</code>, this function runs and properly disposes of all the Three.js objects (geometries, materials, the renderer). This is critical for preventing memory leaks in a React application.</p> </li> </ul>"},{"location":"Frontend/ThreeJS/ThreeJS%20Backend/","title":"Comprehensive Architectural Analysis of the Three.js Rendering Engine: Internal Mechanics, State Management, and Pipeline Optimization","text":""},{"location":"Frontend/ThreeJS/ThreeJS%20Backend/#1-executive-introduction-the-abstraction-of-the-graphics-pipeline","title":"1. Executive Introduction: The Abstraction of the Graphics Pipeline","text":"<p>The domain of real-time web graphics has evolved from rudimentary 2D rasterization to a sophisticated ecosystem capable of rendering photorealistic 3D environments within the browser. At the heart of this evolution lies Three.js, a library that serves as a high-level abstraction layer over the WebGL (Web Graphics Library) and, increasingly, the WebGPU APIs. While the surface-level API of Three.js presents a developer-friendly scene graph\u2014comprising intelligible objects such as <code>Mesh</code>, <code>Camera</code>, <code>Scene</code>, and <code>Material</code>\u2014its internal machinery is a complex orchestration of state management, resource allocation, shader compilation, and linear algebra. This report provides an exhaustive analysis of how Three.js operates \"in the background,\" specifically detailing the lifecycle of a frame from the initial CPU-side matrix updates to the final GPU draw calls.</p> <p>The library's internal architecture is designed to minimize the inherent verbosity of WebGL while attempting to optimize the state machine changes that constitute the primary bottleneck in browser-based graphics. The WebGL API is a state machine that requires precise, sequential commands to configure the Graphics Processing Unit (GPU); a single misstep in state configuration can lead to rendering failures or significant performance degradation. Three.js mitigates this by encapsulating the state in internal classes such as <code>WebGLRenderer</code>, <code>WebGLGeometries</code>, <code>WebGLPrograms</code>, and <code>WebGLBindingStates</code>. Understanding these internal mechanisms is essential for developers seeking to optimize performance beyond the surface-level API, as well as for graphics engineers aiming to extend the engine's capabilities.</p> <p>This analysis is structured to follow the chronological execution of a render frame. It begins with the scene graph propagation on the Central Processing Unit (CPU), moves through the geometry and material processing pipelines, details the sorting and culling algorithms, and concludes with the low-level execution of draw commands and the emerging transition to WebGPU architectures.</p>"},{"location":"Frontend/ThreeJS/ThreeJS%20Backend/#2-the-scene-graph-and-matrix-world-propagation","title":"2. The Scene Graph and Matrix World Propagation","text":"<p>Before any pixels are drawn or any shaders are executed, the engine must determine the spatial relationship of every object in the scene. This process, known as the scene graph update, occurs entirely on the CPU and is the absolute prerequisite for the rendering pipeline. The scene graph is a hierarchical tree structure where nodes (objects) inherit transformations from their parents, creating a dependency chain that must be resolved from the root down to the leaves.</p>"},{"location":"Frontend/ThreeJS/ThreeJS%20Backend/#21-the-hierarchical-transformation-system","title":"2.1. The Hierarchical Transformation System","text":"<p>In Three.js, every renderable object inherits from <code>Object3D</code>. This base class possesses a local transformation state defined by three primary components: <code>position</code> (a <code>Vector3</code>), <code>rotation</code> (represented as either Euler angles or a Quaternion), and <code>scale</code> (a <code>Vector3</code>).[^1] These components constitute the object's \"local\" space\u2014its relationship to its immediate parent. However, the GPU's vertex shader requires the object's absolute position in the world\u2014the <code>modelMatrix</code>\u2014to compute vertex positions in clip space (via the Model-View-Projection matrix sequence).[^2]</p> <p>The synchronization between local transformations and world space is governed by the <code>updateMatrixWorld</code> method. This method functions recursively and is the computational backbone of the scene graph.[^4] The process involves two distinct matrix calculations:</p> <ol> <li>Local Matrix Composition: If the <code>matrixAutoUpdate</code> property is set to <code>true</code>, the engine composes the object's local <code>matrix</code> property from its position, quaternion, and scale. This involves basic matrix multiplication operations to combine translation, rotation, and scaling matrices into a single 4x4 affine transformation matrix.</li> <li>World Matrix Multiplication: The engine then calculates the <code>matrixWorld</code> by multiplying the parent's <code>matrixWorld</code> with the object's newly composed local <code>matrix</code>. This effectively concatenates the transformations, moving the object from its local coordinate system into the global coordinate system of the scene.[^5]</li> </ol> <p>The <code>matrixWorld</code> property is a <code>Matrix4</code> instance representing the object's transformation matrix in world space. If the 3D object has no parent (i.e., it is at the root of the scene graph), <code>matrixWorld</code> is identical to the local transformation matrix.[^1]</p>"},{"location":"Frontend/ThreeJS/ThreeJS%20Backend/#22-mathematical-distinctions-localtoworld-vs-getworldposition","title":"2.2. Mathematical Distinctions: <code>localToWorld</code> vs. <code>getWorldPosition</code>","text":"<p>A nuanced understanding of matrix operations is revealed when examining helper methods like <code>localToWorld</code> and <code>getWorldPosition</code>. While both seem to serve similar purposes, their internal implementations differ significantly in terms of computational cost. <code>localToWorld</code> transforms a vector from the object's local space to world space, effectively applying the object's <code>matrixWorld</code> to the vector. This is a full matrix-vector multiplication. In contrast, <code>getWorldPosition</code> extracts the translation component (the position) directly from the computed <code>matrixWorld</code>. This extraction is computationally cheaper than a full transformation, as it bypasses the rotation and scaling multiplications, merely reading the specific elements (indices 12, 13, and 14) of the 4x4 matrix buffer.[^6] This distinction highlights the importance of understanding the underlying data structures; direct access to matrix elements is often faster than high-level abstraction calls.</p>"},{"location":"Frontend/ThreeJS/ThreeJS%20Backend/#23-optimization-strategies-and-dirty-flags","title":"2.3. Optimization Strategies and Dirty Flags","text":"<p>The traversal of the scene graph can become a significant CPU hotspot, particularly in complex scenes containing thousands of objects or deep hierarchies. To mitigate the performance cost of recomputing matrices for objects that have not moved, Three.js employs a \"dirty flag\" system.</p> <ul> <li><code>matrixWorldNeedsUpdate</code>: This boolean flag is the primary signal for the propagation mechanism. When a parent's matrix is updated, this flag is set to <code>true</code> for the parent and subsequently propagates down the hierarchy to all its children. This forces the children to recalculate their world matrices, ensuring that if a \"car\" object moves, the \"wheel\" children attached to it also move, even if the wheels themselves (local transform) haven't spun.[^1]</li> <li><code>matrixAutoUpdate</code>: By default, this property is set to <code>true</code> for all <code>Object3D</code> instances.[^1] This design choice prioritizes ease of use\u2014developers can simply set <code>mesh.position.x = 10</code> and expect it to work. However, this convenience incurs a performance penalty, as the engine must check and potentially recompose matrices every frame.</li> </ul> <p>Architectural Insight: For static objects\u2014scenery, buildings, or any entity that does not move relative to its parent\u2014the automatic matrix update is a wasted CPU cycle. Optimization requires explicitly setting <code>matrixAutoUpdate = false</code> and <code>matrixWorldAutoUpdate = false</code>. In this configuration, the developer assumes responsibility for calling <code>updateMatrix()</code> or <code>updateMatrixWorld()</code> manually, but only when the object actually moves. In massive scenes, this single change can recover milliseconds of CPU time per frame, which is critical for maintaining a consistent 60Hz refresh rate.[^7]</p> <p>Furthermore, attempting to manually set <code>matrixWorld</code> without managing these flags often leads to the renderer overwriting the manual values during the render loop. The renderer calls <code>scene.updateMatrixWorld()</code> before rendering, which triggers the recursive update. If <code>matrixAutoUpdate</code> is true, any manual changes to <code>matrixWorld</code> will be obliterated by the recomposition of <code>position</code>, <code>rotation</code>, and <code>scale</code>. Therefore, manual matrix management requires a strict adherence to the flag system.[^7]</p>"},{"location":"Frontend/ThreeJS/ThreeJS%20Backend/#24-the-projection-and-coordinate-systems","title":"2.4. The Projection and Coordinate Systems","text":"<p>Once the matrices are updated, the engine can perform geometric projections. The <code>project</code> and <code>unproject</code> methods on <code>Vector3</code> rely on the camera's projection matrix and the object's world matrix to transform coordinates between World Space and Normalized Device Coordinates (NDC). NDC is a cube where x, y, and z range from -1 to 1. This coordinate system is hardware-agnostic and is the final step before the GPU rasterizes geometry onto the 2D screen.[^10]</p> <ul> <li>Project: Transforms a vector from World Space \u2192 Camera Space \u2192 Clip Space \u2192 NDC.</li> <li>Unproject: Transforms a vector from NDC \u2192 Clip Space \u2192 Camera Space \u2192 World Space.</li> </ul> <p>Understanding NDC is vital for tasks like raycasting (picking objects with the mouse), where 2D screen coordinates must be mapped back into the 3D world.[^11] The conversion formula involves the screen width and height, mapping the [0, width] pixel range to the [-1, 1] NDC range.</p>"},{"location":"Frontend/ThreeJS/ThreeJS%20Backend/#3-the-geometry-pipeline-buffers-and-gpu-memory-management","title":"3. The Geometry Pipeline: Buffers and GPU Memory Management","text":"<p>In the modern WebGL pipeline, geometry is not stored as abstract shapes but as streams of binary data. The <code>BufferGeometry</code> class is the interface between JavaScript's dynamic memory and the GPU's static memory buffers. Unlike the legacy <code>Geometry</code> class, which stored vertex data in standard JavaScript arrays and objects (a format that required computationally expensive serialization before rendering), <code>BufferGeometry</code> utilizes <code>TypedArrays</code> (e.g., <code>Float32Array</code>, <code>Uint16Array</code>).[^12] These typed arrays map directly to WebGL buffers, allowing for efficient, zero-copy transfer of data to the graphics card.</p>"},{"location":"Frontend/ThreeJS/ThreeJS%20Backend/#31-the-anatomy-of-buffergeometry","title":"3.1. The Anatomy of <code>BufferGeometry</code>","text":"<p>A <code>BufferGeometry</code> is essentially a container for <code>BufferAttribute</code> instances. Each attribute represents a specific data channel for the vertices:</p> <ul> <li><code>position</code>: The spatial coordinates (x, y, z) of the vertex.</li> <li><code>normal</code>: The direction vector perpendicular to the surface, used for lighting calculations.</li> <li><code>uv</code>: Texture coordinates (u, v) mapping the vertex to a 2D texture image.</li> <li><code>color</code>: Vertex colors (r, g, b).</li> <li>Custom Attributes: Any arbitrary data required by custom shaders (e.g., temperature, velocity, or timestamps).[^14]</li> </ul> <p>These attributes are stored in the <code>.attributes</code> dictionary of the geometry. The data is held in the <code>.array</code> property of the <code>BufferAttribute</code>, which is the <code>TypedArray</code> itself.</p>"},{"location":"Frontend/ThreeJS/ThreeJS%20Backend/#32-the-webglattributes-and-data-upload-mechanism","title":"3.2. The <code>WebGLAttributes</code> and Data Upload Mechanism","text":"<p>The synchronization of geometry data between the CPU (JavaScript) and the GPU (VRAM) is managed by the <code>WebGLAttributes</code> class. This internal module is responsible for creating WebGL buffers (<code>gl.createBuffer</code>), binding them (<code>gl.bindBuffer</code>), and populating them with data (<code>gl.bufferData</code>).[^15]</p> <p>The mechanism for updating data relies on a versioning system. Every <code>BufferAttribute</code> has a <code>.version</code> property.</p> <ol> <li>Initialization: When a geometry is rendered for the first time, <code>WebGLAttributes</code> detects that no WebGL buffer exists for its attributes. It creates the buffers and performs the initial upload using <code>gl.bufferData</code>.[^15]</li> <li>Updates: If a developer modifies the data in the typed array (e.g., morphing a mesh vertex), they must explicitly set the <code>needsUpdate</code> flag to <code>true</code>.<ul> <li>Setting <code>attribute.needsUpdate = true</code> increments the <code>version</code> counter of the attribute.</li> <li>During the next render call, <code>WebGLAttributes</code> checks the version of the attribute against its internal cache.</li> <li>Detecting a version mismatch, it re-uploads the data.</li> </ul> </li> </ol> <p>Performance Criticality: The method used for the upload depends on the usage hint. If the attribute is marked as <code>THREE.DynamicDrawUsage</code>, the engine may use <code>gl.bufferSubData</code> to update only the changed portion, or it may treat the buffer as volatile. If it is <code>THREE.StaticDrawUsage</code> (the default), the engine assumes the data is immutable. Updating a static buffer is computationally expensive as the driver may have placed it in a memory area optimized for reading, not writing. Therefore, correctly flagging the usage type is a primary optimization for dynamic geometry.[^16]</p>"},{"location":"Frontend/ThreeJS/ThreeJS%20Backend/#33-vertex-array-objects-vaos-and-webglbindingstates","title":"3.3. Vertex Array Objects (VAOs) and <code>WebGLBindingStates</code>","text":"<p>In legacy WebGL 1 implementations, binding geometry for a draw call was a verbose process. For a mesh with position, normal, and UV attributes, the renderer had to issue separate <code>gl.bindBuffer</code> and <code>gl.vertexAttribPointer</code> calls for each attribute every single frame.</p> <p>Modern Three.js (utilizing WebGL 2 or the <code>OES_vertex_array_object</code> extension) abstracts this process using Vertex Array Objects (VAOs), managed by the <code>WebGLBindingStates</code> class.[^18] A VAO is a GPU-side object that captures the state of all attribute bindings for a specific geometry-program combination.</p> <ul> <li>Mechanism: When a geometry is first rendered with a specific material (shader), <code>WebGLBindingStates</code> records the binding commands into a VAO.</li> <li>Optimization: For all subsequent frames, the renderer simply binds this single VAO (<code>gl.bindVertexArray</code>). This reduces what could be dozens of WebGL API calls into a single call, significantly reducing the CPU overhead of draw calls.[^20]</li> </ul> <p>State Resetting Implications: The introduction of <code>WebGLBindingStates</code> and VAOs moved attribute management out of the global <code>WebGLState</code>. This has implications for developers mixing raw WebGL calls with Three.js. Using <code>renderer.state.reset()</code> might not fully clear the attribute state encapsulated within a VAO, requiring careful management when interleaving Three.js rendering with custom WebGL commands.[^19]</p>"},{"location":"Frontend/ThreeJS/ThreeJS%20Backend/#34-interleaved-buffers","title":"3.4. Interleaved Buffers","text":"<p>For extreme optimization, particularly in scenarios involving massive particle systems or complex custom shaders, Three.js supports <code>InterleavedBuffer</code>. Standard <code>BufferGeometry</code> uses separate arrays for positions, normals, and colors (Structure of Arrays). <code>InterleavedBuffer</code> packs all these attributes into a single <code>TypedArray</code> (Array of Structures).[^16]</p> <ul> <li>Memory Locality: By keeping all data for a single vertex (position, normal, color) contiguous in memory, interleaved buffers improve cache locality on the GPU. The vertex shader can fetch all attributes for a vertex from a single memory block, reducing memory bandwidth pressure.</li> <li>Implementation: The <code>InterleavedBufferAttribute</code> class points to the shared <code>InterleavedBuffer</code> but defines an <code>offset</code> and <code>itemSize</code> to tell the GPU where to find its specific data within the stride of the buffer.</li> </ul>"},{"location":"Frontend/ThreeJS/ThreeJS%20Backend/#35-storage-buffers-and-compute-shaders-webgpu-transition","title":"3.5. Storage Buffers and Compute Shaders (WebGPU Transition)","text":"<p>As Three.js transitions towards supporting WebGPU via <code>WebGPURenderer</code>, the concept of geometry buffers evolves. <code>StorageBufferAttribute</code> allows data to be used in compute shaders. Unlike traditional attributes which are read-only in the vertex shader, storage buffers can be read and written by compute shaders.[^21]</p> <ul> <li>Mechanism: Developers can create a <code>StorageBufferAttribute</code> and pass it to a <code>StorageBufferNode</code>. This enables entirely GPU-driven logic, such as particle simulations where the position update happens in a compute shader rather than via CPU-side JavaScript updates.</li> <li>No CPU Copy: This architecture allows for \"ping-pong\" simulations where data remains on the GPU indefinitely, eliminating the costly CPU-GPU data transfer bottleneck inherent in <code>gl.bufferData</code>.[^22]</li> </ul>"},{"location":"Frontend/ThreeJS/ThreeJS%20Backend/#4-the-rendering-lifecycle-anatomy-of-the-render-call","title":"4. The Rendering Lifecycle: Anatomy of the <code>.render()</code> Call","text":"<p>The invocation of <code>WebGLRenderer.render(scene, camera)</code> is the trigger that executes the pipeline. This function is synchronous and represents the culmination of all state preparations. It does not include the animation loop itself (managed by <code>requestAnimationFrame</code> or <code>renderer.setAnimationLoop</code>), but performs the work for a single frame.[^2]</p> <p>The rendering lifecycle within Three.js can be dissected into four distinct phases: Initialization, Projection, Sorting, and Rasterization.</p>"},{"location":"Frontend/ThreeJS/ThreeJS%20Backend/#41-phase-1-initialization-and-context-validation","title":"4.1. Phase 1: Initialization and Context Validation","text":"<p>Upon entering the render method, the engine first validates the integrity of the WebGL context. If the context has been lost (e.g., due to the GPU crashing or the browser tab being discarded to save memory), the renderer attempts to restore it or exits gracefully.</p> <p>The renderer then prepares the Render Target. If a <code>WebGLRenderTarget</code> is provided (for rendering to a texture, e.g., for mirrors or post-processing), it binds that target's framebuffer. If <code>null</code> is provided, it binds the default framebuffer, which represents the HTML canvas element.[^2]</p> <p>Clearing Buffers: The <code>autoClear</code> property dictates whether the canvas is wiped clean before drawing. By default, Three.js clears the Color, Depth, and Stencil buffers.</p> <ul> <li>Insight: In complex rendering pipelines involving multiple passes (e.g., a background pass followed by a main scene pass), <code>autoClear</code> must be set to <code>false</code> to prevent the second pass from erasing the first. The developer then manually calls <code>renderer.clear()</code> or <code>renderer.clearDepth()</code> as needed.[^23]</li> </ul>"},{"location":"Frontend/ThreeJS/ThreeJS%20Backend/#42-phase-2-the-projectobject-pipeline","title":"4.2. Phase 2: The <code>projectObject</code> Pipeline","text":"<p>This is the primary CPU-side traversal of the scene graph. <code>projectObject</code> is a recursive function that walks the tree to determine visibility and populate the internal render lists.[^26]</p> <ol> <li>Visibility Check: The first check is the <code>.visible</code> property of the object. If this is <code>false</code>, the recursion terminates for that branch immediately, and neither the object nor its children are processed.[^27]</li> <li>Frustum Culling: If the object is visible, the engine performs frustum culling. It calculates the object's Bounding Sphere and tests for intersection with the camera's Frustum (the pyramid representing the field of view). If <code>.frustumCulled</code> is <code>true</code> (default) and the sphere is outside the frustum, the object is culled and ignored.[^28]<ul> <li>Limitations: Frustum culling relies on the accuracy of the bounding sphere. For objects with skinned animations or displacement shaders, the bounding sphere calculated from the base geometry might be incorrect, leading to objects disappearing when they should be visible (false negatives) or being rendered when they are off-screen (false positives).[^30]</li> </ul> </li> <li>Render List Classification: Objects that pass the culling test are classified and added to a <code>RenderList</code>. Three.js maintains separate lists for different render \"passes\":<ul> <li>Opaque List: For solid objects that fully occlude the background.</li> <li>Transparent List: For objects with alpha blending enabled (<code>material.transparent = true</code>).</li> <li>Transmission List: For physical materials with transmission properties (glass-like refraction).</li> </ul> </li> </ol> <p>The object is not stored directly. Instead, the engine generates a <code>RenderItem</code> struct\u2014a lightweight internal object that captures the state of the object for this specific frame.[^2]</p>"},{"location":"Frontend/ThreeJS/ThreeJS%20Backend/#the-renderitem-struct","title":"The <code>RenderItem</code> Struct","text":"<p>The <code>RenderItem</code> serves as the atomic unit of rendering. It decouples the sorting logic from the object data.</p> Property Description Relevance <code>id</code> Integer A unique identifier for the object, used for stable sorting tie-breaking. <code>object</code> Object3D Reference to the source object (for matrix and user data). <code>geometry</code> BufferGeometry Reference to the geometry (for binding buffers). <code>material</code> Material Reference to the material (for binding programs). <code>program</code> WebGLProgram The compiled shader program associated with the material. <code>groupOrder</code> Integer The user-defined <code>renderOrder</code> property. <code>renderOrder</code> Integer (Redundant naming in some contexts) The priority index. <code>z</code> Float The depth of the object relative to the camera (calculated during projection). <code>group</code> Object Geometry group data (for multi-material meshes)."},{"location":"Frontend/ThreeJS/ThreeJS%20Backend/#43-phase-3-render-list-sorting","title":"4.3. Phase 3: Render List Sorting","text":"<p>Once the lists are populated, they must be sorted to optimize performance and ensure visual correctness. The sorting logic distinguishes clearly between opaque and transparent objects.</p>"},{"location":"Frontend/ThreeJS/ThreeJS%20Backend/#opaque-object-sorting","title":"Opaque Object Sorting","text":"<p>Opaque objects are sorted Front-to-Back (closest to the camera first).</p> <ul> <li>Rationale: This leverages the GPU's Early Z-Culling (or Early-Z). When the GPU processes a fragment (pixel), it checks the Z-buffer. If a pixel has already been drawn at a closer depth, the GPU can discard the new fragment before running the expensive fragment shader. By drawing front-to-back, the engine maximizes the number of discarded fragments for occluded objects.[^33]</li> <li>Material Grouping: Secondary to depth, opaque objects are often grouped by material/program ID. This minimizes state changes (switching shaders is expensive), which is a critical CPU-side optimization.</li> </ul>"},{"location":"Frontend/ThreeJS/ThreeJS%20Backend/#transparent-object-sorting","title":"Transparent Object Sorting","text":"<p>Transparent objects are sorted Back-to-Front (Painter's Algorithm).</p> <ul> <li>Rationale: Alpha blending requires the background color to be present in the frame buffer before the transparent pixel is blended on top of it. If a foreground glass window is drawn before the background tree, the tree will not be visible through the glass because the depth buffer update (if enabled) or blending equation will fail to integrate the background color.[^35]</li> <li>The <code>reversePainterSortStable</code> Naming Confusion: The documentation and internal naming of <code>reversePainterSortStable</code> have caused confusion. A standard Painter's Sort draws from back to front. The function in Three.js sorts based on the Z value. Depending on the projection matrix orientation (Z-forward vs Z-backward), \"reverse\" ensures the order is correct (far Z to near Z). Despite the name, the functional outcome is a Back-to-Front sort.[^33]</li> <li>Limitations of Object Sorting: Three.js sorts based on the object's centroid (or specific position). This works well for distinct objects but fails when large transparent meshes intersect or when a single concave object occludes itself. For accurate transparency in these cases, techniques like splitting meshes or using Order-Independent Transparency (OIT) (not native to Three.js core) are required.[^36]</li> </ul>"},{"location":"Frontend/ThreeJS/ThreeJS%20Backend/#double-sided-transparency","title":"Double-Sided Transparency","text":"<p>Handling <code>DoubleSide</code> transparent materials presents a unique challenge. If drawn in a single pass, the back faces might be drawn after the front faces (depending on vertex order), causing them to be invisible or blend incorrectly.</p> <ul> <li>Mechanism: Three.js internally handles this by splitting the render item into two draw calls. It first renders the back faces (<code>gl.cullFace(gl.FRONT)</code>), then renders the front faces (<code>gl.cullFace(gl.BACK)</code>). This ensures the \"inside\" of a bottle is seen through the \"outside\" correctly.[^38]</li> </ul>"},{"location":"Frontend/ThreeJS/ThreeJS%20Backend/#44-phase-4-rasterization-and-draw-calls","title":"4.4. Phase 4: Rasterization and Draw Calls","text":"<p>The final phase is the execution of the draw commands. The renderer iterates through the sorted lists (Opaque list first, then Transparent list) and calls <code>renderBufferDirect</code>.</p> <ol> <li>Program Switching: The renderer checks if the current <code>RenderItem</code> uses a different <code>WebGLProgram</code> than the previous one. If so, it calls <code>gl.useProgram</code>. This is where sorting by material pays off.</li> <li>Uniform Upload: The <code>WebGLUniforms</code> class uploads the specific data for the object (world matrix, custom uniforms). It uses caching to skip redundant uploads.[^40]</li> <li>State Configuration: The renderer sets the WebGL state (blending, depth test, culling) to match the material properties.</li> <li>Buffer Binding: The <code>WebGLBindingStates</code> module ensures the correct VAO or attributes are bound.[^19]</li> <li>Draw Execution: Finally, <code>gl.drawArrays</code> (for non-indexed geometry) or <code>gl.drawElements</code> (for indexed geometry) is invoked. This sends the command to the GPU driver, which processes the vertices and fragments to produce pixels on the screen.[^18]</li> </ol>"},{"location":"Frontend/ThreeJS/ThreeJS%20Backend/#5-the-material-system-and-shader-compilation-pipeline","title":"5. The Material System and Shader Compilation Pipeline","text":"<p>The declarative Material API of Three.js abstracts the complexity of GLSL (OpenGL Shading Language). However, the engine must ultimately generate valid GLSL code to run on the GPU. This process is dynamic and relies on a sophisticated synthesis system.</p>"},{"location":"Frontend/ThreeJS/ThreeJS%20Backend/#51-shaderchunks-and-composition","title":"5.1. ShaderChunks and Composition","text":"<p>Three.js does not maintain a library of static, pre-written shader files for every possible material configuration. Instead, it uses ShaderChunks\u2014atomic snippets of GLSL code stored in <code>THREE.ShaderChunk</code>. These chunks handle specific lighting models, texturing logic, or utility functions (e.g., <code>fog_pars_fragment</code>, <code>lights_phong_pars_fragment</code>).[^42]</p> <p>When a material is initialized:</p> <ol> <li>Template Retrieval: The engine retrieves the base template for the material type (e.g., the <code>MeshStandardMaterial</code> template).</li> <li>Chunk Injection: It parses the template and replaces placeholder strings (<code>#include &lt;chunk_name&gt;</code>) with the actual GLSL code from the <code>ShaderChunk</code> library.</li> <li>Defines Injection: The engine inspects the capabilities of the hardware and the settings of the scene. It injects <code>#define</code> statements at the top of the shader.<ul> <li>Example: If the scene has a fog object, <code>#define USE_FOG</code> is added. If the renderer supports logarithmic depth buffers, <code>#define USE_LOGDEPTHBUF</code> is added. These defines act as preprocessor switches, conditionally compiling sections of the shader code.</li> </ul> </li> </ol>"},{"location":"Frontend/ThreeJS/ThreeJS%20Backend/#52-the-program-cache-and-getprogramcachekey","title":"5.2. The Program Cache and <code>getProgramCacheKey</code>","text":"<p>Shader compilation is a blocking operation on the main thread and is one of the most expensive tasks in the rendering pipeline. To prevent \"jank\" (stuttering), Three.js implements a robust caching system via <code>WebGLPrograms</code>.</p> <p>For every material encountered, the renderer generates a Program Cache Key. This key is a long, unique string signature that encodes every factor influencing the shader's source code:</p> <ul> <li>Material parameters (type, side, blending, encoding).</li> <li>Texture presence (map, envMap, normalMap).</li> <li>Scene state (number and type of lights, fog configuration).</li> <li>Renderer settings (tone mapping, output encoding).[^44]</li> </ul> <p>The Caching Logic:</p> <ol> <li>The renderer generates the key for the current material/scene configuration.</li> <li>It checks <code>WebGLPrograms</code> for an existing program with this key.</li> <li>Hit: If found, the existing compiled program is reused. This enables thousands of distinct <code>MeshStandardMaterial</code> instances (e.g., different colors) to share a single GLSL program, provided their structural configuration (defines) is identical.[^44]</li> <li>Miss: If not found, the engine synthesizes the GLSL string, compiles the vertex and fragment shaders, links the program, and stores it in the cache.</li> </ol> <p>Recompilation Triggers: Because the cache key depends on the scene state, adding a light to a scene that previously had none changes the key (e.g., from <code>NUM_DIR_LIGHTS 0</code> to <code>NUM_DIR_LIGHTS 1</code>). This forces a recompilation of all materials affected by lighting. This is why adding lights at runtime can cause a momentary freeze.[^46]</p>"},{"location":"Frontend/ThreeJS/ThreeJS%20Backend/#53-onbeforecompile-and-customization","title":"5.3. <code>onBeforeCompile</code> and Customization","text":"<p>The <code>onBeforeCompile</code> callback provides a hook into this pipeline. It allows developers to intercept the shader source string after chunk injection but before compilation. This enables the modification of built-in materials (e.g., adding a noise function to the vertex position) without rewriting the entire shader from scratch.</p> <p>Cache Implications: Since Three.js cannot analyze the logic inside a user's <code>onBeforeCompile</code> function, it cannot automatically determine if the modification is unique. Developers must implement <code>customProgramCacheKey()</code> to return a unique identifier for their patch. Failure to do so will result in different patched materials sharing the same (incorrect) program from the cache, or the patch being ignored.[^47]</p>"},{"location":"Frontend/ThreeJS/ThreeJS%20Backend/#6-advanced-internal-mechanisms","title":"6. Advanced Internal Mechanisms","text":""},{"location":"Frontend/ThreeJS/ThreeJS%20Backend/#61-shadow-map-rendering","title":"6.1. Shadow Map Rendering","text":"<p>Rendering shadows is a multi-pass process that occurs transparently within the <code>render()</code> call.</p> <ol> <li>The Shadow Pass: Before the main scene is drawn, the renderer iterates through all light sources that cast shadows.</li> <li>Internal Render Targets: It switches the render target to an internal <code>WebGLRenderTarget</code> (the shadow map).</li> <li>Material Override: It renders the scene from the light's perspective. Crucially, it overrides the scene materials with <code>MeshDepthMaterial</code> (or <code>MeshDistanceMaterial</code> for point lights). This material only records the depth of objects, ignoring color and textures, which makes the pass efficient.[^2]</li> <li>Frustum Culling (Shadow Camera): The culling logic is applied using the light's shadow camera frustum, ensuring only objects visible to the light are rendered to the shadow map.</li> <li>Integration: During the main render pass, these shadow maps are bound as textures to the main materials. The <code>shadowmap_pars_fragment</code> chunk in the shader samples these textures to determine occlusion.[^1]</li> </ol>"},{"location":"Frontend/ThreeJS/ThreeJS%20Backend/#62-instanced-rendering-instancedmesh","title":"6.2. Instanced Rendering (<code>InstancedMesh</code>)","text":"<p>For scenes with thousands of identical objects (e.g., trees, debris), <code>InstancedMesh</code> leverages Hardware Instancing.</p> <ul> <li>Mechanism: Instead of issuing 1000 draw calls for 1000 trees, the engine issues a single draw call. The transformation matrices for all instances are stored in a <code>InstancedBufferAttribute</code> (effectively a texture or a large buffer).</li> <li>Shader Modification: The vertex shader is modified to read the transformation matrix from this attribute based on the <code>gl_InstanceID</code>.</li> <li>Culling Limitation: A significant limitation of standard <code>InstancedMesh</code> is that frustum culling operates on the entire batch. If the bounding sphere of the entire forest is visible, all trees are processed by the vertex shader, even those behind the camera. Advanced users often implement custom culling logic to update the instance count dynamically or use libraries like <code>InstancedMesh2</code> that perform per-instance culling.[^20]</li> </ul>"},{"location":"Frontend/ThreeJS/ThreeJS%20Backend/#63-webgl-state-management-and-resets","title":"6.3. WebGL State Management and Resets","text":"<p>The <code>WebGLState</code> class tracks the global state of the WebGL context (blending modes, face culling, depth testing).</p> <ul> <li>Redundant Call Prevention: Before issuing a command like <code>gl.enable(gl.DEPTH_TEST)</code>, it checks its internal cache. If depth testing is already enabled, the call is skipped.</li> <li>Context Sharing Issues: If a developer executes raw WebGL commands alongside Three.js (e.g., using a third-party physics debug renderer that uses raw GL), the Three.js state cache becomes desynchronized. The <code>renderer.resetState()</code> method must be called to invalidate the cache and force Three.js to re-apply its state on the next frame.[^19]</li> </ul>"},{"location":"Frontend/ThreeJS/ThreeJS%20Backend/#7-the-webgpu-transition","title":"7. The WebGPU Transition","text":"<p>The introduction of <code>WebGPURenderer</code> marks a paradigm shift in the engine's backend. While <code>WebGLRenderer</code> is bound by the state-machine architecture of OpenGL, <code>WebGPURenderer</code> utilizes a more modern, command-buffer-based approach.</p> <ul> <li>Pipeline Objects: Instead of dynamic state changes, WebGPU uses immutable Render Pipelines.</li> <li>Compute Shaders: <code>StorageBufferAttribute</code> allows data to be manipulated by Compute Shaders, enabling physics simulations and particle systems to run entirely on the GPU without CPU round-trips.[^21]</li> <li>Node Material System: The shift to WebGPU is accompanied by a move towards a Node Material system (TSL - Three.js Shading Language), which abstracts shader generation even further, allowing materials to be composed graph-based rather than string-based.[^52]</li> </ul>"},{"location":"Frontend/ThreeJS/ThreeJS%20Backend/#8-conclusion","title":"8. Conclusion","text":"<p>The architecture of Three.js is a testament to the challenge of balancing abstraction with performance. By encapsulating the WebGL state machine, the engine allows developers to think in terms of objects and scenes rather than buffers and bindings. However, this convenience relies on a complex infrastructure of dirty flags, version counters, and caching mechanisms.</p> <p>The engine's performance is largely dictated by how well the developer's code aligns with these internal mechanisms. Minimizing matrix updates via <code>matrixAutoUpdate = false</code>, leveraging the <code>BufferAttribute</code> versioning system correctly, grouping objects to optimize sorting, and understanding the shader recompilation triggers are the keys to unlocking the full potential of the renderer. As the ecosystem moves toward WebGPU, these fundamental concepts of buffer management and pipeline state will remain relevant, even as the underlying API calls evolve.</p>"},{"location":"Frontend/ThreeJS/ThreeJS%20Backend/#works-cited","title":"Works cited","text":"<ol> <li>Object3D.matrixWorld \u2013 three.js docs, accessed November 22, 2025, https://threejs.org/docs/#api/en/core/Object3D.matrixWorld</li> <li>Renderer \u2013 three.js docs, accessed November 22, 2025, https://threejs.org/docs/pages/Renderer.html</li> <li>How THREE.js Abstracts Away The Complexities of Programming 3D Graphics - Medium, accessed November 22, 2025, https://medium.com/@evmaperry/how-three-js-abstracts-away-the-complexities-of-programming-3d-graphics-c3b74dbf051c</li> <li>Object3D.updateMatrixWorld \u2013 three.js docs, accessed November 22, 2025, https://threejs.org/docs/#api/en/core/Object3D.updateMatrixWorld</li> <li>Question about Object3D.updateMatrixWorld() - three.js forum, accessed November 22, 2025, https://discourse.threejs.org/t/question-about-object3d-updatematrixworld/6925</li> <li>localToWorld vs getWorldPosition - Questions - three.js forum, accessed November 22, 2025, https://discourse.threejs.org/t/localtoworld-vs-getworldposition/76101</li> <li>[SOLVED] How to update matrices manually? - Questions - three.js forum, accessed November 22, 2025, https://discourse.threejs.org/t/solved-how-to-update-matrices-manually/1154</li> <li>what is the usage of three js Object3D.matrixWorldAutoUpdate and updateMatrixWorld() api? - Stack Overflow, accessed November 22, 2025, https://stackoverflow.com/questions/74052761/what-is-the-usage-of-three-js-object3d-matrixworldautoupdate-and-updatematrixwor</li> <li>Setting matrixWorld property of a three.js object - Stack Overflow, accessed November 22, 2025, https://stackoverflow.com/questions/37446330/setting-matrixworld-property-of-a-three-js-object</li> <li>How project(camera) work in threejs? - Questions - three.js forum, accessed November 22, 2025, https://discourse.threejs.org/t/how-project-camera-work-in-threejs/50969</li> <li>How to understand Vector3.project and NDC space - Questions - three.js forum, accessed November 22, 2025, https://discourse.threejs.org/t/how-to-understand-vector3-project-and-ndc-space/26535</li> <li>Is there any way to delete a buffer in threejs to reduce GPU memory leak? - Stack Overflow, accessed November 22, 2025, https://stackoverflow.com/questions/38705897/is-there-any-way-to-delete-a-buffer-in-threejs-to-reduce-gpu-memory-leak</li> <li>Why is the Geometry faster than BufferGeometry? - Questions - three.js forum, accessed November 22, 2025, https://discourse.threejs.org/t/why-is-the-geometry-faster-than-buffergeometry/574</li> <li>BufferGeometry \u2013 three.js docs, accessed November 22, 2025, https://threejs.org/docs/#api/en/core/BufferGeometry</li> <li>Three.js Buffer Management - javascript - Stack Overflow, accessed November 22, 2025, https://stackoverflow.com/questions/42392777/three-js-buffer-management</li> <li>Updating buffer attribute performance is incredibly slow - Questions - three.js forum, accessed November 22, 2025, https://discourse.threejs.org/t/updating-buffer-attribute-performance-is-incredibly-slow/36415</li> <li>WebGL: INVALID_ENUM: bufferData: invalid usage with model from external source, accessed November 22, 2025, https://discourse.threejs.org/t/webgl-invalid-enum-bufferdata-invalid-usage-with-model-from-external-source/13087</li> <li>three.js docs, accessed November 22, 2025, https://threejs.org/docs/</li> <li>Renderer state.reset() no longer resets attributes \u00b7 Issue #20549 \u00b7 mrdoob/three.js - GitHub, accessed November 22, 2025, https://github.com/mrdoob/three.js/issues/20549</li> <li>Three.js Instancing - How does it work? - Questions, accessed November 22, 2025, [https://discourse.threejs.org/t/three-js-instancing-how-does-it-work/32664](https://discourse.threejs.org/t/three-js-instancing-how-does-it-work/32664</li> <li>StorageBufferAttribute - Three.js Docs, accessed November 22, 2025, https://threejs.org/docs/pages/StorageBufferAttribute.html</li> <li>GPUBuffer to BufferAttribute - Questions - three.js forum, accessed November 22, 2025, https://discourse.threejs.org/t/gpubuffer-to-bufferattribute/73531</li> <li>WebGLRenderer.render \u2013 three.js docs, accessed November 22, 2025, https://threejs.org/docs/#api/en/renderers/WebGLRenderer.render</li> <li>WebGLRenderer \u2013 three.js docs, accessed November 22, 2025, https://threejs.org/docs/#api/en/renderers/WebGLRenderer</li> <li>WebGLRenderer.sortObjects \u2013 three.js docs, accessed November 22, 2025, https://threejs.org/docs/#api/renderers/WebGLRenderer.sortObjects</li> <li>mrdoob/three.js: JavaScript 3D Library. - GitHub, accessed November 22, 2025, https://github.com/mrdoob/three.js/</li> <li>UpdateMatrixWorld Performance - Questions - three.js forum, accessed November 22, 2025, https://discourse.threejs.org/t/updatematrixworld-performance/3217</li> <li>Object3D.frustumCulled \u2013 three.js docs, accessed November 22, 2025, https://threejs.org/docs/#api/core/Object3D.frustumCulled</li> <li>[SOLVED] How can we get a list of objects that Three.js is rendering inside the camera (not frustum culled)?, accessed November 22, 2025, https://discourse.threejs.org/t/solved-how-can-we-get-a-list-of-objects-that-three-js-is-rendering-inside-the-camera-not-frustum-culled/5164</li> <li>Ideas on performing fast per-instance frustum culling on InstancedMesh - three.js forum, accessed November 22, 2025, https://discourse.threejs.org/t/ideas-on-performing-fast-per-instance-frustum-culling-on-instancedmesh/85156</li> <li>How to do frustum culling with instancedMesh? - Questions - three.js forum, accessed November 22, 2025, https://discourse.threejs.org/t/how-to-do-frustum-culling-with-instancedmesh/22633</li> <li>Is \"currentRenderList.finish();\" necessary? - Questions - three.js forum, accessed November 22, 2025, https://discourse.threejs.org/t/is-currentrenderlist-finish-necessary/23023</li> <li>Naming of <code>reverseStablePainterSort</code> but it seems to actually be painter sort, not reverse?, accessed November 22, 2025, https://discourse.threejs.org/t/naming-of-reversestablepaintersort-but-it-seems-to-actually-be-painter-sort-not-reverse/63007</li> <li>ThreeJS and the transparent problem - Questions - three.js forum, accessed November 22, 2025, https://discourse.threejs.org/t/threejs-and-the-transparent-problem/11553</li> <li>three.js - renderOrder doesn't work when the scene has transparent objects - Stack Overflow, accessed November 22, 2025, https://stackoverflow.com/questions/44730037/renderorder-doesnt-work-when-the-scene-has-transparent-objects</li> <li>Easiest way to set rendering order for transparent objects - Questions - three.js forum, accessed November 22, 2025, https://discourse.threejs.org/t/easiest-way-to-set-rendering-order-for-transparent-objects/25372</li> <li>How to render transparent Object in correct order or looks like right\uff1f - three.js forum, accessed November 22, 2025, https://discourse.threejs.org/t/how-to-render-transparent-object-in-correct-order-or-looks-like-right/47568</li> <li>Material.side \u2013 three.js docs, accessed November 22, 2025, https://threejs.org/docs/#api/materials/Material.side</li> <li>artifacts when rendering both sides of a transparent object with three.js - Stack Overflow, accessed November 22, 2025, https://stackoverflow.com/questions/13221328/artifacts-when-rendering-both-sides-of-a-transparent-object-with-three-js</li> <li>Where in source code does ThreeJS perform updates to WebGL uniforms that are Objects?, accessed November 22, 2025, https://discourse.threejs.org/t/where-in-source-code-does-threejs-perform-updates-to-webgl-uniforms-that-are-objects/6056</li> <li>WebGL How It Works, accessed November 22, 2025, https://webglfundamentals.org/webgl/lessons/webgl-how-it-works.html</li> <li>ShaderMaterial.defines \u2013 three.js docs, accessed November 22, 2025, https://threejs.org/docs/#api/en/materials/ShaderMaterial.defines</li> <li>How to create custom shaders using THREE.ShaderLib - Stack Overflow, accessed November 22, 2025, https://stackoverflow.com/questions/49060488/how-to-create-custom-shaders-using-three-shaderlib</li> <li>Material.customProgramCacheKey \u2013 three.js docs, accessed November 22, 2025, https://threejs.org/docs/#api/en/materials/Material.customProgramCacheKey</li> <li>Use faster program cache key computation. \u00b7 Issue #22530 \u00b7 mrdoob/three.js - GitHub, accessed November 22, 2025, https://github.com/mrdoob/three.js/issues/22530</li> <li>How to determine if a material has failed to compile? - three.js forum, accessed November 22, 2025, https://discourse.threejs.org/t/how-to-determine-if-a-material-has-failed-to-compile/48761</li> <li>Material.onBeforeCompile \u2013 three.js docs, accessed November 22, 2025, https://threejs.org/docs/#api/en/materials/Material.onBeforeCompile</li> <li>Material material.onBeforeCompile problem for three.js - Questions, accessed November 22, 2025, https://discourse.threejs.org/t/material-material-onbeforecompile-problem-for-three-js/53340</li> <li><code>onBeforeCompile</code> fires only once, although I set <code>needsUpdate = true</code> - three.js forum, accessed November 22, 2025, https://discourse.threejs.org/t/onbeforecompile-fires-only-once-although-i-set-needsupdate-true/38614</li> <li>InstancedBufferGeometry not updated properly between render calls \u00b7 Issue #22843 \u00b7 mrdoob/three.js - GitHub, accessed November 22, 2025, https://github.com/mrdoob/three.js/issues/22843</li> <li>WebGLRenderer.initTexture \u2013 three.js docs, accessed November 22, 2025, https://threejs.org/docs/#api/en/renderers/WebGLRenderer.initTexture</li> <li>WebGLRenderer: Add support for Node Materials \u00b7 Issue #30185 \u00b7 mrdoob/three.js - GitHub, accessed November 22, 2025, https://github.com/mrdoob/three.js/issues/30185</li> </ol>"},{"location":"Frontend/ThreeJS/CadToThreeJS/","title":"Architectures for Parametric CAD in Three.js","text":"<p>This document provides a high-level overview of the different architectural patterns for bringing parametric CAD (Computer-Aided Design) models into a real-time 3D web application like Three.js.</p>"},{"location":"Frontend/ThreeJS/CadToThreeJS/#the-core-problem-logic-vs-geometry","title":"The Core Problem: Logic vs. Geometry","text":"<p>The fundamental challenge is that a native CAD file (e.g., from Inventor or SolidWorks) is a \"recipe,\" not a \"model.\" It contains a feature tree\u2014a step-by-step history of operations like <code>extrude</code>, <code>cut</code>, and <code>fillet</code>, along with mathematical parameters and constraints.</p> <p>Web formats like <code>glTF</code>/<code>glb</code> are \"dumb\" meshes. They are the final, flattened geometry (like a JPG) and contain no information about the recipe used to create them.</p> <p>The goal, therefore, is to re-create the parametric \"recipe\" logic in the browser. We have discussed three primary architectures to achieve this, ranging from a common \"dead end\" to highly robust, professional solutions.</p>"},{"location":"Frontend/ThreeJS/CadToThreeJS/#1-the-gltf-json-mapping-approach-the-dead-end","title":"1. The \"glTF + JSON\" Mapping Approach (The Dead End)","text":"<p>This is the most common first idea. It's an intuitive approach that unfortunately fails in practice.</p> <ul> <li> <p>The Theory: Export a <code>model.glb</code> (the geometry) and a <code>params.json</code> (the parameters) from your CAD program. In Three.js, load the <code>.glb</code> and then try to \"map\" the JSON parameters to the mesh vertices. When a parameter changes (e.g., <code>width = 110</code>), you find all the vertices associated with \"width\" and move them in JavaScript.</p> </li> <li> <p>The Verdict: This is a dead end. A CAD model's topology (its vertex and triangle structure) is not stable. Changing one parameter (like a fillet radius or a hole count) causes the CAD engine to re-calculate and generate a completely new mesh\u2014it doesn't just \"move\" vertices. The vertex IDs, count, and order all change, making any static mapping impossible.</p> </li> <li> <p>Learn more: In-depth: Why the \"glTF + JSON\" Approach Fails</p> </li> </ul>"},{"location":"Frontend/ThreeJS/CadToThreeJS/#2-the-feature-tree-transpiler-approach-the-compiler","title":"2. The \"Feature Tree Transpiler\" Approach (The \"Compiler\")","text":"<p>This is the most powerful, complex, and \"pure\" solution. It treats the entire process as a compiler pipeline.</p> <ul> <li> <p>The Theory: You invent your own \"Intermediate Representation\" (a custom JSON schema) that describes the entire feature tree as a list of operations (e.g., <code>{\"type\": \"SKETCH\"}</code>, <code>{\"type\": \"EXTRUDE\"}</code>).</p> <ol> <li>Frontend (Plugin): You write a custom plugin for each CAD program (Inventor, SolidWorks) to \"transpile\" their proprietary feature tree into your standard JSON \"recipe.\"</li> <li>Backend (Web App): Your JavaScript code acts as an \"interpreter\" or \"compiler\" that reads this JSON recipe. It walks the feature tree step-by-step and issues low-level commands to a geometry kernel (like Manifold3D) to build the model from scratch.</li> </ol> </li> <li> <p>The Verdict: This is the most flexible and scalable solution, as it creates a true, generic CAD program in the browser. It is also by far the most difficult, requiring you to build and maintain multiple complex CAD plugins and a sophisticated JavaScript interpreter.</p> </li> <li> <p>Learn more: In-depth: The \"Feature Tree to Manifold\" (Transpiler) Architecture</p> </li> </ul>"},{"location":"Frontend/ThreeJS/CadToThreeJS/#3-the-domain-specific-generator-approach-the-emulator","title":"3. The \"Domain-Specific\" Generator Approach (The \"Emulator\")","text":"<p>This is the pragmatic and highly effective solution you are implementing. It \"fakes\" the CAD logic by specializing in a specific domain (e.g., furniture).</p> <ul> <li> <p>The Theory: Instead of translating a generic feature tree, you write specific JavaScript functions (e.g., <code>buildCabinet(params)</code>, <code>buildTable(params)</code>). This code doesn't read a recipe; it is the recipe. It knows how to build a cabinet from scratch using simple math (e.g., <code>shelfWidth = totalWidth - (2 * boardThickness)</code>). It generates simple primitives (like boxes for boards) and \"assembles\" them using a kernel like Manifold3D.</p> </li> <li> <p>The Verdict: This is the fastest and most robust solution for product configurators. It avoids 99% of the complexity of \"real\" CAD. It's decoupled, meaning the web visual can be a simple \"wrapper\" of boards, while the \"real\" CAD model for manufacturing can be far more detailed.</p> </li> <li> <p>Learn more: In-depth: The \"Domain-Specific\" (Wrapping) Architecture</p> </li> </ul>"},{"location":"Frontend/ThreeJS/CadToThreeJS/#comparison-summary","title":"Comparison Summary","text":"Approach How it Works Key Challenge Verdict glTF + JSON \"Modify\" an existing <code>.glb</code> mesh by moving vertices. Unstable topology. Fails on any real-world model. Dead End Transpiler \"Re-builds\" a model by interpreting a JSON feature tree. Extreme complexity. Requires custom plugins for each CAD program. The \"Pure\" (Hardest) Way Domain-Specific \"Re-builds\" a model using hard-coded generative logic (e.g., <code>buildCabinet()</code>). Limited to a specific domain (e.g., \"board furniture\"). The Pragmatic (Best) Way"},{"location":"Frontend/ThreeJS/CadToThreeJS/FeatureTreeToManifold3d/","title":"Feature Tree Transpiling","text":""},{"location":"Frontend/ThreeJS/CadToThreeJS/FeatureTreeToManifold3d/#the-transpiler-architecture-a-viable-path-for-parametric-cad","title":"The \"Transpiler\" Architecture: A Viable Path for Parametric CAD","text":"<p>This document explains the \"Compiler/Transpiler\" model for creating a parametric 3D web application. This is the correct, robust, and scalable alternative to the \"glTF + JSON\" approach.</p> <p>Instead of modifying existing geometry, this architecture rebuilds the entire 3D model from scratch on every parameter change. This is made possible by a fast, client-side geometry kernel.</p>"},{"location":"Frontend/ThreeJS/CadToThreeJS/FeatureTreeToManifold3d/#1-the-core-concept-a-compiler-pipeline","title":"1. The Core Concept: A Compiler Pipeline","text":"<p>Think of this entire system as a compiler, which has three distinct parts. This analogy is the key to understanding the workflow.</p> <ol> <li> <p>The Frontend (The CAD Plugin):</p> <ul> <li>What it is: A custom plugin you write for your \"source\" CAD software (e.g., Inventor, SolidWorks).</li> <li>Job: To \"parse\" the proprietary, native feature tree and translate it into a universal, intermediate language.</li> </ul> </li> <li> <p>The Intermediate Representation (IR):</p> <ul> <li>What it is: Your custom \"JSON Contract\" or \"Feature Tree.\"</li> <li>Job: To represent the design intent (the step-by-step recipe) in a simple, standardized, text-based format. This is your \"Abstract Syntax Tree\" (AST).</li> </ul> </li> <li> <p>The Backend (The Web App):</p> <ul> <li>What it is: Your JavaScript/TypeScript code running in the browser.</li> <li>Job: To \"compile\" or \"interpret\" the JSON (the IR) into \"machine code\"\u2014a series of low-level commands that a geometry kernel can execute.</li> </ul> </li> </ol>"},{"location":"Frontend/ThreeJS/CadToThreeJS/FeatureTreeToManifold3d/#2-the-core-components-in-detail","title":"2. The Core Components in Detail","text":""},{"location":"Frontend/ThreeJS/CadToThreeJS/FeatureTreeToManifold3d/#component-a-the-json-recipe-the-intermediate-representation","title":"Component A: The JSON \"Recipe\" (The Intermediate Representation)","text":"<p>This is the file you custom-export from your CAD software. It is not just a list of parameters. It is a step-by-step history of operations that reference those parameters.</p> <p>Example <code>recipe.json</code>:</p> <pre><code>{\n  \"parameters\": {\n    \"width\": 100,\n    \"length\": 150,\n    \"thickness\": 20,\n    \"hole_diam\": 15\n  },\n  \"history\": [\n    {\n      \"id\": \"base_sketch\",\n      \"type\": \"SKETCH_2D\",\n      \"plane\": \"XY\",\n      \"shapes\": [\n        { \"type\": \"rect\", \"x\": 0, \"y\": 0, \"w\": \"width\", \"h\": \"length\" }\n      ]\n    },\n    {\n      \"id\": \"base_solid\",\n      \"type\": \"EXTRUDE\",\n      \"target\": \"base_sketch\",\n      \"depth\": \"thickness\"\n    },\n    {\n      \"id\": \"hole_cutout\",\n      \"type\": \"CYLINDER\",\n      \"radius\": \"hole_diam / 2\",\n      \"height\": \"thickness + 10\",\n      \"position\": [\"width / 2\", \"length / 2\", 0]\n    },\n    {\n      \"id\": \"final_part\",\n      \"type\": \"BOOLEAN_CUT\",\n      \"target\": \"base_solid\",\n      \"tool\": \"hole_cutout\"\n    }\n  ]\n}\n</code></pre>"},{"location":"Frontend/ThreeJS/CadToThreeJS/FeatureTreeToManifold3d/#component-b-the-javascript-translator-the-interpreter","title":"Component B: The JavaScript \"Translator\" (The Interpreter)","text":"<p>This is the core of your web application. It is a tree walker that uses the \"Visitor\" pattern. Its job is to read the <code>history</code> array from the JSON and call the Manifold3D API.</p> <p>Example <code>translator.js</code> (Simplified):</p> <pre><code>// (Assumes Manifold3D WASM module is loaded as 'manifold')\n\nclass ParametricEngine {\n  constructor() {\n    this.cache = new Map(); // Stores features by ID (e.g., 'base_solid')\n  }\n\n  // Main function to build the model\n  build(contract) {\n    this.cache.clear();\n    const params = contract.parameters;\n\n    // 1. Create a parameter evaluator\n    // (This is a helper that safely evaluates \"width / 2\" to 50)\n    const eval = (expr) =&gt; this.evaluate(expr, params);\n\n    // 2. Walk the feature tree\n    for (const step of contract.history) {\n      switch (step.type) {\n\n        case 'SKETCH_2D':\n          // Creates a 2D Manifold.CrossSection object\n          const poly = manifold.CrossSection.rectangle(\n            eval(step.shapes[0].w), \n            eval(step.shapes[0].h)\n          );\n          this.cache.set(step.id, poly);\n          break;\n\n        case 'EXTRUDE':\n          // Get the 2D sketch from the cache\n          const sketch = this.cache.get(step.target);\n          const depth = eval(step.depth);\n\n          // Call Manifold API\n          const solid = manifold.Manifold.extrude(sketch, depth);\n          this.cache.set(step.id, solid);\n          break;\n\n        case 'CYLINDER':\n          const r = eval(step.radius);\n          const h = eval(step.height);\n          const pos = [eval(step.position[0]), eval(step.position[1]), eval(step.position[2])];\n\n          // Call Manifold API\n          let cyl = manifold.Manifold.cylinder(h, r);\n          cyl = cyl.translate(pos);\n          this.cache.set(step.id, cyl);\n          break;\n\n        case 'BOOLEAN_CUT':\n          // Get the two solids from the cache\n          const target = this.cache.get(step.target);\n          const tool = this.cache.get(step.tool);\n\n          // Call Manifold API\n          const result = manifold.Manifold.difference(target, tool);\n          this.cache.set(step.id, result);\n          break;\n      }\n    }\n\n    // Return the final feature\n    return this.cache.get(contract.history.at(-1).id);\n  }\n\n  evaluate(expr, params) {\n    // In production, use a safe math parser, NOT eval()!\n    if (typeof expr === 'number') return expr;\n    let str = expr.toString();\n    for (const [key, val] of Object.entries(params)) {\n      str = str.replaceAll(key, val);\n    }\n    return new Function(`return ${str}`)();\n  }\n}\n</code></pre>"},{"location":"Frontend/ThreeJS/CadToThreeJS/FeatureTreeToManifold3d/#component-c-the-manifold3d-kernel-the-machine","title":"Component C: The Manifold3D Kernel (The \"Machine\")","text":"<p>This is the \"dumb\" but powerful engine. It doesn't know what a \"feature tree\" is. It only knows how to execute low-level commands passed to it by the Translator.</p>"},{"location":"Frontend/ThreeJS/CadToThreeJS/FeatureTreeToManifold3d/#3-the-full-workflow-step-by-step","title":"3. The Full Workflow (Step-by-Step)","text":"<p>Here is what happens when a user changes a parameter:</p> <ol> <li> <p>Initial Load:</p> <ul> <li>The browser loads your web app, the <code>Manifold3D.wasm</code> module, and the <code>recipe.json</code> for a default model.</li> <li>The <code>ParametricEngine</code> runs <code>build(recipe)</code> for the first time.</li> <li>It generates the final <code>Manifold</code> object.</li> <li>You convert this object to a <code>THREE.BufferGeometry</code> and add it to your scene.</li> </ul> </li> <li> <p>User Interaction:</p> <ul> <li>A user moves a UI slider, changing <code>parameters.width</code> from <code>100</code> to <code>110</code>.</li> </ul> </li> <li> <p>The Re-Build:</p> <ul> <li>You call <code>engine.build(recipe)</code> again with the new parameters.</li> <li>The engine throws away all old results in its cache.</li> <li>It re-runs the entire history from top to bottom, but this time using <code>width = 110</code>.</li> <li><code>SKETCH_2D</code>: Creates a wider 2D rectangle.</li> <li><code>EXTRUDE</code>: Extrudes the wider sketch.</li> <li><code>CYLINDER</code>: Re-creates the cylinder at the new position (<code>width / 2</code> is now <code>55</code>).</li> <li><code>BOOLEAN_CUT</code>: Subtracts the cylinder from the wider block.</li> <li>The whole process takes 5-10 milliseconds.</li> </ul> </li> <li> <p>The Render:</p> <ul> <li>The <code>build()</code> function returns the new <code>Manifold</code> object.</li> <li>You dispose of the old <code>BufferGeometry</code> in Three.js (to prevent memory leaks).</li> <li>You create a new <code>BufferGeometry</code> from the new Manifold object and put it in the scene.</li> <li>To the user, the model appears to have \"updated instantly.\"</li> </ul> </li> </ol>"},{"location":"Frontend/ThreeJS/CadToThreeJS/FeatureTreeToManifold3d/#4-the-real-work-challenges","title":"4. The \"Real\" Work &amp; Challenges","text":"<p>This architecture is robust, but the work is significant. The complexity is no longer in Three.js, but in building the translator.</p> <ol> <li> <p>The Exporter Plugin (The #1 Hurdle):     This is the \"Compiler Frontend.\" You must write a plugin for SolidWorks (C#), Inventor (VBA/iLogic), or Fusion 360 (Python) that can read the real feature tree and export your custom JSON. This is a complex, software-specific task.</p> </li> <li> <p>2D Sketch Engine:     My example used a simple rectangle. A real translator needs to read/execute complex 2D sketches with lines, arcs, and constraints. This is a major engineering task in itself.</p> </li> <li> <p>Topological Referencing (The \"Hard Problem\"):     My JSON used math (<code>width / 2</code>). A real CAD model uses topology (<code>sketch on this face</code>, <code>fillet on this edge</code>). When the model rebuilds, \"Face #3\" might become \"Face #5\". You must build a system to reliably track these relationships. This is the hardest part of CAD development.</p> </li> <li> <p>Fillets and Chamfers (The Kernel Limitation):     Manifold3D is a CSG kernel and does not have simple commands for fillets or chamfers. You must implement the math for these yourself (e.g., by creating a \"negative\" torus shape and subtracting it), which is extremely difficult.</p> </li> </ol>"},{"location":"Frontend/ThreeJS/CadToThreeJS/GLB%2BParameters/","title":"The \"glTF + JSON\" Parametric Theory (And Why It's a Dead End)","text":"<p>This document outlines the common theoretical approach for creating a web-based CAD configurator by mapping a JSON parameter file to a static <code>glTF</code>/<code>glb</code> model. It then explains the fundamental reasons why this method fails in practice.</p>"},{"location":"Frontend/ThreeJS/CadToThreeJS/GLB%2BParameters/#the-dream-workflow-how-it-should-work","title":"The \"Dream\" Workflow: How It Should Work","text":"<p>The idea is to decouple the logic (parameters) from the geometry (the mesh), which seems clean and efficient.</p> <p>The theoretical process would look like this:</p> <ol> <li> <p>Export from CAD:</p> <ul> <li><code>model.glb</code>: The base 3D geometry. This is the visual \"mesh\" of the model.</li> <li><code>params.json</code>: A custom-exported file containing all parameters and rules (e.g., <code>{\"width\": 100, \"height\": 200, \"hole_count\": 3}</code>).</li> </ul> </li> <li> <p>Load in Three.js:</p> <ul> <li>The <code>GLTFLoader</code> loads the <code>model.glb</code> and creates a standard <code>THREE.Mesh</code> with a <code>BufferGeometry</code>.</li> <li>A <code>fetch</code> request loads the <code>params.json</code> into a JavaScript object.</li> </ul> </li> <li> <p>The \"Magic\" Mapping:</p> <ul> <li>This is the core assumption. The theory assumes you can find a stable link between the parameters and the geometry.</li> <li>For example, your code would know that the parameter <code>\"width\"</code> corresponds to a specific group of vertices on the side of the mesh.</li> </ul> </li> <li> <p>Execute Parameter Change:</p> <ul> <li>A user moves a slider, changing <code>\"width\"</code> from 100 to 110.</li> <li>Your JavaScript code would:<ol> <li>Get all vertices \"tagged\" with <code>\"width\"</code>.</li> <li>Loop through them and update their X-position in the <code>geometry.attributes.position</code> buffer (e.g., <code>vertex.x += 10</code>).</li> <li>Call <code>geometry.attributes.position.needsUpdate = true</code> to tell Three.js to re-draw the modified shape.</li> </ol> </li> </ul> </li> </ol> <p>The Core Assumption: This entire process hinges on the belief that changing a parameter is a simple translation (moving) of existing vertices, and that those vertices can be reliably identified.</p>"},{"location":"Frontend/ThreeJS/CadToThreeJS/GLB%2BParameters/#the-dead-end-why-this-fails","title":"The Dead End: Why This Fails","text":"<p>This \"modify-in-place\" approach fails because a CAD model's geometry is far more complex than a simple \"bag of vertices.\" The relationship between parameters and geometry is not a simple 1-to-1 mapping.</p>"},{"location":"Frontend/ThreeJS/CadToThreeJS/GLB%2BParameters/#1-the-dumb-mesh-problem","title":"1. The \"Dumb Mesh\" Problem","text":"<p>A <code>glTF</code> or <code>glb</code> file is a \"dumb\" mesh format. It is an optimized and \"flattened\" list of triangles. It has no concept of: * Faces * Edges * Holes * Fillets * Or \"width\"</p> <p>It only contains a giant array of <code>(x, y, z)</code> coordinates for its vertices. When you export from Inventor, all the \"intelligence\" that defined the part is completely discarded.</p>"},{"location":"Frontend/ThreeJS/CadToThreeJS/GLB%2BParameters/#2-the-topological-naming-problem","title":"2. The Topological Naming Problem","text":"<p>This is the most critical failure point. Even if you could \"tag\" vertices in your CAD program (e.g., \"Vertex #501\" = \"part_of_width_face\"), this information is lost during export.</p> <ul> <li>CAD programs perform mesh optimization when exporting.</li> <li>Vertices are merged (e.g., if two edges meet, their shared vertices become one).</li> <li>The entire vertex buffer is re-indexed.</li> </ul> <p>The \"Vertex #501\" in your Inventor file might become \"Vertex #1204\" in the <code>.glb</code> file, or it might be optimized away entirely. The link is broken instantly.</p>"},{"location":"Frontend/ThreeJS/CadToThreeJS/GLB%2BParameters/#3-the-non-linear-problem-the-real-killer","title":"3. The \"Non-Linear\" Problem (The Real Killer)","text":"<p>This is the fatal flaw in the theory. Changing a parameter is not a simple translation of vertices.</p> <p>Changing a parameter causes the CAD software to re-calculate the entire model's topology.</p> <p>Consider these examples: * A Simple Fillet (Rounded Edge): You increase the <code>width</code> of a box. The flat face's vertices do just move. But the fillet that connects it to the top face must be completely re-calculated. The old fillet's vertices are deleted, and a new set of vertices with a new curve is created. * A Pattern Feature: Your model has a <code>hole_count</code> parameter. Changing it from <code>3</code> to <code>4</code> doesn't move anything. It creates new geometry (a new cylinder to cut) and adds new vertices to the mesh. * A Boolean Feature: You decrease the <code>width</code> of a part. The new width is now smaller than a hole that was cut into it. The CAD program's logic says \"this hole feature no longer touches the part,\" so the feature is suppressed. The hole (and all its vertices) disappears entirely.</p> <p>The vertex count, face count, and triangle order are not stable. They change dramatically with almost every parameter update.</p>"},{"location":"Frontend/ThreeJS/CadToThreeJS/Wrapping/","title":"Object Wrapping","text":""},{"location":"Frontend/ThreeJS/CadToThreeJS/Wrapping/#the-domain-specific-generative-architecture","title":"The \"Domain-Specific\" Generative Architecture","text":"<p>This document outlines a \"hybrid\" or \"emulated logic\" approach for a parametric web configurator. This architecture is designed for a specific domain (e.g., furniture made from wooden boards) and avoids the extreme complexity of 1:1 CAD feature tree translation.</p> <p>It works by faking the CAD logic in JavaScript and using the web app as a \"parameter generator\" that can (optionally) feed data back to a simplified, \"real\" CAD model for manufacturing.</p>"},{"location":"Frontend/ThreeJS/CadToThreeJS/Wrapping/#1-the-core-philosophy-generate-dont-translate","title":"1. The Core Philosophy: \"Generate, Don't Translate\"","text":"<p>The fundamental flaw of other methods is trying to translate a complex, interdependent feature tree. This architecture abandons that idea.</p> <p>Instead, you write a JavaScript engine that knows how to build your product (e.g., a cabinet) from scratch, using its own logic. This logic is much simpler because it's only concerned with the final placement of the boards, not the complex CAD-level sketches, constraints, or feature dependencies.</p> <p>You are not building a generic CAD program; you are building a bookshelf generator.</p>"},{"location":"Frontend/ThreeJS/CadToThreeJS/Wrapping/#2-the-web-side-workflow-the-board-generator","title":"2. The Web-Side Workflow (The \"Board Generator\")","text":"<p>This is where all the \"magic\" happens. Your web app is a standalone generative engine.</p> <ol> <li> <p>Input: The \"import\" is not a 3D model. The input is a simple JSON object of high-level parameters, e.g., <code>{\"model\": \"bookshelf\", \"width\": 800, \"height\": 1800, \"shelfCount\": 4}</code>.</p> </li> <li> <p>The \"Fake\" Logic Engine: You write specific JavaScript functions for each furniture type:</p> <ul> <li><code>buildBookshelf(params)</code></li> <li><code>buildCabinet(params)</code></li> <li><code>buildTable(params)</code></li> </ul> </li> <li> <p>The Process (The Math):     Inside <code>buildBookskey(params)</code>, your code doesn't care about \"extrusions\" or \"features.\" It just does simple math to create a \"shopping list\" of parts (boards) and their dimensions/positions.</p> <p>```javascript // Example logic inside your buildBookshelf() function: const boardThickness = 18; const sideHeight = params.height; const sideWidth = params.depth; const topWidth = params.width; const shelfWidth = params.width - (2 * boardThickness);</p> <p>// Board 1: Left Side let leftBoard = Manifold.cube([boardThickness, sideWidth, sideHeight])                        .translate([-params.width / 2, 0, 0]);</p> <p>// Board 2: Right Side let rightBoard = Manifold.cube([boardThickness, sideWidth, sideHeight])                         .translate([params.width / 2 - boardThickness, 0, 0]);</p> <p>// Board 3: Top Board let topBoard = Manifold.cube([topWidth, sideWidth, boardThickness])                       .translate([-params.width / 2, 0, params.height - boardThickness]);</p> <p>// ... etc. for other boards and shelves ... ```</p> </li> <li> <p>The Assembly:     Your <code>build</code> function ends by \"assembling\" all the individual board objects using Manifold3D's <code>union</code> operation. This creates a single, clean 3D model from many simple primitives.</p> <p>```javascript // Combine all the parts into one model let finalModel = Manifold.union(leftBoard, rightBoard, topBoard /, ...all_other_boards/);</p> <p>// This 'finalModel' is what you convert to a BufferGeometry for Three.js return finalModel; ```</p> <p>This is what you mean by \"piecing the building shapes together.\" You are generating and \"gluing\" (union-ing) them in real-time.</p> </li> </ol>"},{"location":"Frontend/ThreeJS/CadToThreeJS/Wrapping/#3-the-cad-side-workflow-the-data-round-trip","title":"3. The CAD-Side Workflow (The \"Data Round-Trip\")","text":"<p>This is the clever part of your system. You are creating a \"decoupled\" workflow where the web app and the \"real\" CAD file are two separate systems that only share simple parameters.</p>"},{"location":"Frontend/ThreeJS/CadToThreeJS/Wrapping/#a-web-to-cad-exporting-for-manufacturing","title":"A) Web-to-CAD (Exporting for Manufacturing)","text":"<p>Your web app's primary job is to generate a simple JSON file of the final, calculated dimensions.</p> <ol> <li> <p>Web App: User finalizes their 800mm wide bookshelf. Your app generates a <code>manufacturing_params.json</code>:</p> <p><code>json {   \"side_panel_height\": 1800,   \"side_panel_width\": 300,   \"top_panel_width\": 800,   \"shelf_panel_width\": 764 }</code></p> </li> <li> <p>CAD Software (Inventor/SolidWorks):</p> <ul> <li>You have a separate, \"real\" CAD model of the bookshelf. This model is also parametric, but it is linked to an external JSON file.</li> <li>You use a simple plugin (like iLogic in Inventor) to read <code>manufacturing_params.json</code>.</li> <li>The plugin maps the JSON values to the \"real\" model's parameters (e.g., <code>InventorParam(\"side_height\") = json.side_panel_height</code>).</li> <li>The \"real\" CAD model updates, and you can now instantly generate your \"real\" factory drawings and CAM paths.</li> </ul> </li> </ol>"},{"location":"Frontend/ThreeJS/CadToThreeJS/Wrapping/#b-cad-to-web-importing-generic-models","title":"B) CAD-to-Web (Importing \"Generic Models\")","text":"<p>This is the reverse. \"Importing a model\" simply means creating a new <code>config.json</code> file that tells your web app which generator to use and which parameters to show.</p> <ul> <li>You don't import a <code>glb</code>.</li> <li>You just create a new JSON file like:     <code>json     {       \"generator_function\": \"buildCabinet\",       \"configurable_params\": [         { \"name\": \"width\", \"min\": 600, \"max\": 1200 },         { \"name\": \"height\", \"min\": 1000, \"max\": 2200 },         { \"name\": \"hasDoubleDoors\", \"type\": \"boolean\" }       ]     }</code></li> <li>Your web app reads this file and dynamically builds the UI sliders and checkboxes.</li> </ul>"},{"location":"Frontend/ThreeJS/CadToThreeJS/Wrapping/#4-why-this-architecture-is-a-win","title":"4. Why This Architecture is a \"Win\"","text":"<ul> <li>It's Simple: You avoid 99% of the complexity of CAD. Your logic is just <code>width - (2 * thickness)</code>.</li> <li>It's Fast: Re-building a dozen boxes with Manifold3D is instantaneous (milliseconds).</li> <li>It's Not a \"Dead End\": This system is robust and scalable. To add a new product (e.g., a dresser), you just write a new <code>buildDresser(params)</code> function. You don't have to change the core engine.</li> <li>It's Decoupled: The \"web model\" and the \"manufacturing model\" are totally separate. This is a huge advantage. If the manufacturing model needs to add complex details (like dowel holes or specific hardware), it doesn't break your web visual. The web app only needs to send the high-level parameters.</li> </ul>"},{"location":"Marktstrategie%20%26%20Analyse/Einordnung%20%26%20Marktpotenzial/","title":"Einordnung & Marktpotenzial","text":"<p>Das Projekt adressiert ein echtes, allt\u00e4gliches Problem und kombiniert Design, Individualisierung, Digitalisierung und Automatisierung auf intelligente Weise. Dadurch hat das Konzept das Potenzial f\u00fcr eine sehr hohe Skalierbarkeit. </p>"},{"location":"Marktstrategie%20%26%20Analyse/Einordnung%20%26%20Marktpotenzial/#1-markt-und-grundidee","title":"1. Markt und Grundidee","text":"<p>Warum die Idee gut ist:</p> <p>Millionen Balkone in Europa sind:  - zu klein f\u00fcr Standardm\u00f6bel - schlecht genutzt - optisch lieblos</p> <p>Menschen wollen: - Gem\u00fctlichkeit - Individualit\u00e4t - einfache L\u00f6sungen</p> <p>Ma\u00dfanfertigungen gibt es --&gt; aber: - teuer - langsam - nicht digital - nicht skalierbar</p> <p>Das Konzept positioniert sich zwischen IKEA &amp; Schreiner - und bietet damit enorme Umsatzchancen.</p>"},{"location":"Marktstrategie%20%26%20Analyse/Einordnung%20%26%20Marktpotenzial/#2-starken-der-idee","title":"2. St\u00e4rken der Idee","text":""},{"location":"Marktstrategie%20%26%20Analyse/Einordnung%20%26%20Marktpotenzial/#mass-customization-sehr-stark","title":"Mass Customization (sehr stark)","text":"<ul> <li>Ma\u00dfanfertigung</li> <li>Trotzdem standardisierte Module</li> <li>Ideal f\u00fcr Automatisierung</li> </ul>"},{"location":"Marktstrategie%20%26%20Analyse/Einordnung%20%26%20Marktpotenzial/#digitaler-konfigurator","title":"Digitaler Konfigurator","text":"<ul> <li>Weckt Emotionen (Spiel, Vorfreude)</li> <li>Reduziert Beratungskosten</li> <li>Skaliert international</li> </ul>"},{"location":"Marktstrategie%20%26%20Analyse/Einordnung%20%26%20Marktpotenzial/#hoher-wahrgenommener-wert","title":"Hoher wahrgenommener Wert","text":"<ul> <li>Balkon bedeutet Lebensqualit\u00e4t</li> <li>Sinnvolle ansprechende Wohnraumerweiterung, statt ungenutzte kalte Fl\u00e4che</li> </ul>"},{"location":"Marktstrategie%20%26%20Analyse/Einordnung%20%26%20Marktpotenzial/#klare-zielgruppe","title":"Klare Zielgruppe","text":"<ul> <li>Stadtbewohner</li> <li>Mieter &amp; Eigent\u00fcmer</li> <li>Design-affin, aber pragmatisch</li> </ul>"},{"location":"Marktstrategie%20%26%20Analyse/Einordnung%20%26%20Marktpotenzial/#geringe-rucksendequote-wenn-konzept-gut-umgesetzt","title":"Geringe R\u00fccksendequote (wenn Konzept gut umgesetzt)","text":"<ul> <li>Ma\u00dfanfertigung bedeutet bewusste Kaufentscheidung</li> </ul>"},{"location":"Marktstrategie%20%26%20Analyse/Kundenbeduerfnisse/","title":"Kundenbed\u00fcrfnisse f\u00fcr Balkonm\u00f6bel","text":"<p>Damit wir ein passendes Produkt entwickeln und erfolgreich vermarkten k\u00f6nnen, ist es wichtig, die zentralen Bed\u00fcrfnisse und Erwartungen der Kunden an Balkonm\u00f6bel zu verstehen. Diese lassen sich in verschiedene Kategorien einteilen:</p>"},{"location":"Marktstrategie%20%26%20Analyse/Kundenbeduerfnisse/#1-funktionale-bedurfnisse","title":"1. Funktionale Bed\u00fcrfnisse","text":"<ul> <li>Platzsparend: Besonders in St\u00e4dten sind Balkone oft klein. M\u00f6bel sollten klappbar, stapelbar oder modular sein.  </li> <li>Komfort: Trotz kompakter Gr\u00f6\u00dfe w\u00fcnschen sich viele Kunden bequeme Sitzm\u00f6glichkeiten.  </li> <li>Wetterfestigkeit: M\u00f6bel m\u00fcssen Regen, Sonne und Temperaturschwankungen standhalten.  </li> <li>Leichte Reinigung: Praktische Materialien, die unkompliziert abwischbar sind, sind gefragt.  </li> </ul>"},{"location":"Marktstrategie%20%26%20Analyse/Kundenbeduerfnisse/#2-emotionale-bedurfnisse","title":"2. Emotionale Bed\u00fcrfnisse","text":"<ul> <li>Individuelles Design: Kunden m\u00f6chten M\u00f6bel, die ihren pers\u00f6nlichen Stil widerspiegeln.  </li> <li>Wohlf\u00fchlatmosph\u00e4re: M\u00f6bel sollen den Balkon in einen gem\u00fctlichen R\u00fcckzugsort verwandeln.  </li> <li>Prestige/\u00c4sthetik: F\u00fcr manche ist die Optik wichtiger als die Funktion \u2013 ein Statement Piece.  </li> </ul>"},{"location":"Marktstrategie%20%26%20Analyse/Kundenbeduerfnisse/#3-okonomische-bedurfnisse","title":"3. \u00d6konomische Bed\u00fcrfnisse","text":"<ul> <li>Preis-Leistungs-Verh\u00e4ltnis: Viele suchen eine bezahlbare L\u00f6sung mit ansprechender Qualit\u00e4t.  </li> <li>Langlebigkeit: M\u00f6bel sollen sich als Investition lohnen und nicht jedes Jahr ersetzt werden m\u00fcssen.  </li> <li>Nachhaltigkeit: Wachsende Zielgruppe achtet auf umweltfreundliche Materialien und Produktion.  </li> </ul>"},{"location":"Marktstrategie%20%26%20Analyse/Kundenbeduerfnisse/#4-praktische-zusatzbedurfnisse","title":"4. Praktische Zusatzbed\u00fcrfnisse","text":"<ul> <li>Einfache Lieferung &amp; Aufbau: M\u00f6bel sollen unkompliziert geliefert und montiert werden k\u00f6nnen.  </li> <li>Flexibilit\u00e4t: M\u00f6bel, die sich leicht umstellen oder erweitern lassen, sind attraktiv.  </li> <li>Stauraum-L\u00f6sungen: Integrierte Aufbewahrung kann ein Zusatznutzen sein.  </li> </ul>"},{"location":"Marktstrategie%20%26%20Analyse/Kundenbeduerfnisse/#bedeutung-einer-umfrage","title":"Bedeutung einer Umfrage","text":"<p>Um diese Bed\u00fcrfnisse nicht nur theoretisch zu sammeln, sondern auch quantitativ zu \u00fcberpr\u00fcfen, eignet sich eine Kundenumfrage. Eine Umfrage hilft uns dabei: - Priorit\u00e4ten der Kunden zu erkennen (z. B. ist Preis wichtiger als Design?). - Zielgruppen besser zu verstehen (z. B. junge Stadtbewohner vs. Familien). - Produktideen direkt mit echten Erwartungen abzugleichen.  </p> <p>Auf diese Weise k\u00f6nnen wir unser Produkt gezielt auf die wichtigsten Bed\u00fcrfnisse zuschneiden und Fehlentwicklungen vermeiden.</p> <p>## Hierzu wurde eine Umfrage in Microsoft Forms erstellt: Hier klicken, um an der Umfrage mitzuarbeiten</p>"},{"location":"Marktstrategie%20%26%20Analyse/Marktanalyse/","title":"Marktanalyse \u2013 \u00dcberblick","text":"<p>Die Marktanalyse dient dazu, die Erfolgschancen f\u00fcr das Gesch\u00e4ftsmodell \u201eindividuelle Balkonm\u00f6bel auf Ma\u00df\u201c realistisch einzusch\u00e4tzen. Sie umfasst die Untersuchung von Kundenbed\u00fcrfnissen, Konkurrenzprodukten und der potenziellen Zielgruppe. Zus\u00e4tzlich sollen Daten \u00fcber eine eigene Umfrage gesammelt werden, um die Annahmen mit realem Feedback zu validieren.</p>"},{"location":"Marktstrategie%20%26%20Analyse/Marktanalyse/#themenbereiche-der-marktanalyse","title":"Themenbereiche der Marktanalyse","text":"<ul> <li> <p>\ud83e\udde9 Kundenbed\u00fcrfnisse   Welche Anforderungen und W\u00fcnsche haben Kund:innen an individuelle Balkonm\u00f6bel?   (z. B. Preis, Materialqualit\u00e4t, einfache Montage, Nachhaltigkeit, Lieferzeit)</p> </li> <li> <p>\ud83d\udcca Konkurrenzanalyse   Welche Anbieter und Produkte gibt es bereits am Markt?   Welche St\u00e4rken und Schw\u00e4chen zeigen diese im Vergleich zum geplanten Konzept?</p> </li> <li> <p>\ud83c\udfaf Zielgruppe   Wer sind die potenziellen Kund:innen?   (z. B. Altersgruppen, Einkommensniveau, Wohnsituation, Lifestyle-Trends)</p> </li> </ul>"},{"location":"Marktstrategie%20%26%20Analyse/Marktanalyse/#datengrundlage-kundenumfrage","title":"Datengrundlage: Kundenumfrage","text":"<p>Zur besseren Einsch\u00e4tzung der Kundenbed\u00fcrfnisse wird eine Online-Umfrage mit Microsoft Forms durchgef\u00fchrt. Die Ergebnisse sollen in das Kapitel Kundenbed\u00fcrfnisse einflie\u00dfen.  </p> <p>Beispielhafte Fragen der Umfrage: - Welche Faktoren sind Ihnen bei Balkonm\u00f6beln am wichtigsten? - W\u00fcrden Sie einen Online-Konfigurator zur individuellen Anpassung nutzen? - Welche Preisspanne erscheint Ihnen realistisch? - Wie wichtig sind Nachhaltigkeit und regionale Produktion?  </p>"},{"location":"Marktstrategie%20%26%20Analyse/Marktanalyse/#ziel-der-marktanalyse","title":"Ziel der Marktanalyse","text":"<ul> <li>Identifikation der relevanten Kundenbed\u00fcrfnisse </li> <li>Ermittlung der Zielgruppe und deren Gr\u00f6\u00dfe  </li> <li>Analyse des Wettbewerbsumfelds </li> <li>Ableitung einer Marktstrategie, die das geplante Angebot optimal positioniert</li> </ul>"},{"location":"Marktstrategie%20%26%20Analyse/Businessplan/Businessplan/","title":"Businessplan","text":"<p>Test: Pedro erkl\u00e4rt mir Github.</p>"},{"location":"Marktstrategie%20%26%20Analyse/Konkurrenzanalyse/Ikea/","title":"An Analysis of the Multi-Layered Market Impact of IKEA's Digital Configurator Suite","text":""},{"location":"Marktstrategie%20%26%20Analyse/Konkurrenzanalyse/Ikea/#i-executive-summary","title":"I. Executive Summary","text":"<p>This report provides a comprehensive analysis of the market impact of IKEA's digital configurator tools, with a primary focus on the progression from the 3D Kitchen Planner to the new AI-driven IKEA Kreativ platform. The analysis demonstrates that the market impact of these configurators is not as a simple sales tool but as a sophisticated, multi-layered strategic system. This system is central to IKEA's market-driving strategy. [1] Its impact operates on four distinct levels simultaneously:</p> <ul> <li>Psychological: It systematically manufactures deep brand loyalty and increases willingness to pay by operationalizing documented cognitive biases, specifically the \"IKEA Effect,\" in a digital environment.</li> <li>Commercial: It directly drives commercial outcomes by guiding customers through complex purchases, reducing purchase friction and anxiety, which in turn boosts conversion rates and significantly lowers the high logistical cost of product returns.</li> <li>Operational: It functions as a massive labor-optimization engine, shifting low-value, time-consuming planning work from paid staff to unpaid customers, thereby re-allocating internal resources to higher-value, personalized service.</li> <li>Informational: It operates as IKEA's most powerful proprietary data-gathering asset, transforming millions of user-generated designs into a structured, forward-looking data pipeline. This data pipeline provides the critical fuel for IKEA's back-end AI-driven supply chain and \"Demand Sensing\" intelligence systems.</li> </ul>"},{"location":"Marktstrategie%20%26%20Analyse/Konkurrenzanalyse/Ikea/#ii-the-configurator-as-ikeas-core-engine-for-value-co-creation","title":"II. The Configurator as IKEA's Core Engine for Value Co-Creation","text":"<p>The IKEA planner is the central mechanism through which the company executes its \"co-creation\" strategy, transforming passive consumers into active design partners. [2] The 3D planner [4] serves as the primary interface for what the company frames as a \"personal experience\". [5] This strategy explicitly moves beyond the mere sale of furniture to engage customers in \"lifestyle design\" [5], thereby fulfilling a core strategic objective of deeply understanding customer needs and preferences. [6]</p> <p>This \"co-creation\" model, however, presents a strategic dilemma: the desire to leverage customer interaction versus the inherent risk of losing brand control. [3] The IKEA configurator suite is the definitive solution to this problem. For the user, the planner provides a powerful, gamified feeling of free, personal creativity and autonomy\u2014a sense of \"design incorporated\" into their own lives. [5]</p> <p>From a market strategy perspective, this tool functions as a \"walled garden.\" Every component, layout, and \"choice\" the customer can make has been pre-determined, pre-approved, and pre-integrated into IKEA's product catalog and supply chain. The planner's primary market function, therefore, is to provide the immense psychological benefits of autonomy and co-creation without incurring any of the strategic risks of brand dilution. It is a controlled ecosystem that expertly guides a customer's \"creativity\" toward a single, pre-ordained, purchase-ready outcome.</p>"},{"location":"Marktstrategie%20%26%20Analyse/Konkurrenzanalyse/Ikea/#iii-the-psychological-architecture-of-digital-co-creation-the-ikea-effect","title":"III. The Psychological Architecture of Digital Co-Creation: The \"IKEA Effect\"","text":"<p>The most profound market impact of the IKEA configurator is its ability to systematically leverage human psychology. The planner is a digital factory for manufacturing the \"IKEA Effect,\" a cognitive bias scientifically documented to increase a consumer's valuation of products they help create. [7]</p>"},{"location":"Marktstrategie%20%26%20Analyse/Konkurrenzanalyse/Ikea/#labor-leads-to-love-defining-the-ikea-effect","title":"\"Labor Leads to Love\": Defining the IKEA Effect","text":"<p>A foundational paper from the Harvard Business School defines the \"IKEA Effect\" as the \"increase in valuation of self-made products\". [7] The study's authors note that this effect emerges from the labor itself. The effort a user expends\u2014dragging, dropping, measuring, and iterating within the kitchen planner\u2014is a form of digital labor. This labor psychologically increases their \"love\" for and \"willingness to pay\" for the final, self-designed kitchen.</p> <p>Crucially, this effect is distinct from the value derived from customization. [7] While the planner does offer customization, the HBS study found that the IKEA Effect arises from labor alone, even on standardized products. [7] The planner gamifies this value-creating labor, making it feel like \"play\" [8] while simultaneously cementing the user's psychological investment.</p>"},{"location":"Marktstrategie%20%26%20Analyse/Konkurrenzanalyse/Ikea/#the-neural-basis-of-attachment-from-business-theory-to-biophysics","title":"The Neural Basis of Attachment: From Business Theory to Biophysics","text":"<p>This business theory is validated by hard-science research. A 2023 fNIRS neuroimaging study examining the IKEA effect provides a neural basis for this phenomenon. [9] The study found that evaluating self-assembled (DIY) products triggers differential cortical activation in specific brain regions: the left-inferior frontal gyrus (L-IFG) and the left-middle frontal gyrus (L-MFG). [9] These brain regions are scientifically linked to memory and attachment. [9]</p> <p>This discovery reveals the planner's true mechanism. The IKEA effect is described as a \"compound effect\" of attachment and memory retrieval. [9] The planner, by being a visual, iterative, and goal-oriented tool, is effectively a machine for building these positive memories and attachments before the product even exists. The customer is not just designing a kitchen; they are creating a digital memory. This \"pre-emptive nostalgia\" for their own creation generates a powerful emotional barrier to defection. The customer is no longer just buying cabinets; they are buying the physical manifestation of the hours they spent planning, dreaming, and, most importantly, successfully completing a task. [7]</p>"},{"location":"Marktstrategie%20%26%20Analyse/Konkurrenzanalyse/Ikea/#the-fragility-of-the-effect-uiux-as-a-strategic-imperative","title":"The Fragility of the Effect: UI/UX as a Strategic Imperative","text":"<p>This psychological mechanism is also a significant business risk. The HBS paper notes a critical boundary condition: labor leads to love only when it results in the successful completion of tasks. [7] When labor is frustrating or results in failure, the effect dissipates or even inverts, leading to decreased valuation.</p> <p>This is directly reflected in user complaints about the planner being \"laggy, glitchy, buggy, slow as molasses\". [10] A poorly functioning planner does not just create neutral friction; it actively destroys brand value. The user's labor is no longer successful and creative, but futile and frustrating. This makes the tool's technical performance and user-experience (UI/UX) design a mission-critical, strategic imperative, not a simple design choice.</p>"},{"location":"Marktstrategie%20%26%20Analyse/Konkurrenzanalyse/Ikea/#iv-technological-evolution-from-blank-pages-to-ai-driven-mixed-reality","title":"IV. Technological Evolution: From Blank Pages to AI-Driven Mixed Reality","text":"<p>IKEA's configurator suite has evolved in a clear, logical progression, with each new technology being deployed to solve a specific market barrier identified in the previous generation.</p>"},{"location":"Marktstrategie%20%26%20Analyse/Konkurrenzanalyse/Ikea/#phase-1-the-3d-kitchen-planner","title":"Phase 1: The 3D Kitchen Planner","text":"<p>The baseline tool was a web-based, 3D planner that required no download, a key innovation at its time. [11] Its primary function was to bring complex, 3D spatial planning\u2014once the domain of professionals\u2014to the mass market, allowing users to \"craft a personalized layout\". [4]</p>"},{"location":"Marktstrategie%20%26%20Analyse/Konkurrenzanalyse/Ikea/#phase-2-the-new-3d-planner-the-blank-page-problem","title":"Phase 2: The \"New\" 3D Planner &amp; The \"Blank Page\" Problem","text":"<p>IKEA's own analysis identified a key flaw in the original planner: starting with a \"blank page\" is intimidating and a significant barrier to engagement. [8] The new 3D planner, announced in late 2025, solves this by allowing users to \"start with inspiration, not a blank page\". [8] This new version is a guided experience, adding critical features like real-time price updates as users design, and a smartphone measurement tool to make the process \"faster, easier, and more inspiring\". [8]</p>"},{"location":"Marktstrategie%20%26%20Analyse/Konkurrenzanalyse/Ikea/#phase-3-the-ar-revolution-ikea-place","title":"Phase 3: The AR Revolution (IKEA Place)","text":"<p>Launched in 2017, the IKEA Place app was built on Apple's ARKit. [13] It was designed to solve a different problem: the \"imagination gap\" and \"will-it-fit\" anxiety for individual product purchases. The app offers 98% scale accuracy, allowing users to \"confidently experience, experiment and share\" products in their own space. [13] Its impact is primarily about reducing uncertainty and allowing customers to \"try before they buy\". [14]</p>"},{"location":"Marktstrategie%20%26%20Analyse/Konkurrenzanalyse/Ikea/#phase-4-the-ai-powered-synthesis-ikea-kreativ","title":"Phase 4: The AI-Powered Synthesis (IKEA Kreativ)","text":"<p>Launched in 2022, IKEA Kreativ is the synthesis of all previous efforts. It is powered by the 2020 acquisition of the Silicon Valley AI specialist Geomagical Labs. [16] Kreativ uses AI neural networks and spatial computing to solve the ultimate psychological barrier to purchase: status quo bias, or the attachment to one's existing furniture.</p> <p>The strategic pivot of Kreativ is its \"erase\" function. While IKEA Place added digital items to a physical room, Kreativ first scans the user's room to create a 3D replica, and then \"digitally erase[s] their existing furniture\". [16] This automation of erasure is a profound psychological nudge. It manufactures a \"clean slate\" [18] and allows the user to build their new reality without the cognitive friction of their old one, dramatically accelerating the path from inspiration to purchase. The acquisition of Geomagical Labs demonstrates IKEA understood this \"erasure\" capability was a core strategic technology to be owned, not licensed.</p>"},{"location":"Marktstrategie%20%26%20Analyse/Konkurrenzanalyse/Ikea/#table-1-evolution-of-ikeas-digital-configurator-suite","title":"Table 1: Evolution of IKEA's Digital Configurator Suite","text":"Tool Approx. Launch Core Technology Key Strategic Function Source(s) 3D Kitchen Planner ~2000s Web-based 3D Rendering Mass-Market Complex Co-Creation: Empowers users to design complex, multi-item projects (kitchens). 4 IKEA Place 2017 Augmented Reality (AR) Single-Item Risk Reduction: Solves the \"will-it-fit\" problem by placing 3D models in a real room. 13 New 3D Kitchen Planner 2025 3D Web, Mobile Integration Reduce Planning Friction: Solves the \"blank page problem\" with inspiration templates; adds real-time pricing. 8 IKEA Kreativ 2022 AI, Mixed Reality (MR), Spatial Computing Full-Room AI-Powered Redesign: Solves \"status quo bias\" by erasing old furniture to create a \"clean slate.\" 16"},{"location":"Marktstrategie%20%26%20Analyse/Konkurrenzanalyse/Ikea/#v-quantifiable-market-impact-a-review-of-commercial-and-customer-metrics","title":"V. Quantifiable Market Impact: A Review of Commercial and Customer Metrics","text":"<p>While much of the configurator's impact is psychological and operational, it translates directly into quantifiable commercial metrics.</p>"},{"location":"Marktstrategie%20%26%20Analyse/Konkurrenzanalyse/Ikea/#direct-sales-conversion-and-pipeline","title":"Direct Sales, Conversion, and Pipeline","text":"<p>The market impact of IKEA's digital engagement tools is most evident in its conversion metrics. Analysis of IKEA's digital marketing shows that users who engage with Augmented Reality (AR) features (like IKEA Place) exhibit a 90% increase in conversion rates compared to those who do not. [19] This demonstrates the power of risk-reduction technologies.</p> <p>For high-consideration purchases like kitchens, the metrics shift from immediate conversion to pipeline capture. A single kitchen sale is not an impulse buy. The new 3D kitchen planner is part of a strategic initiative to generate over 1.75 million kitchen projects annually. [8] This figure represents a massive, captured pipeline of high-intent, high-value customers whom IKEA can nurture within its ecosystem for the months-long duration of their decision-making process. This initiative is a cornerstone of a broader campaign to increase sales volumes of the cooking and eating range by 10% by FY26. [8]</p>"},{"location":"Marktstrategie%20%26%20Analyse/Konkurrenzanalyse/Ikea/#customer-confidence-and-risk-reduction","title":"Customer Confidence and Risk Reduction","text":"<p>A primary commercial function of the tools is the reduction of uncertainty, which is the single biggest barrier to online furniture sales. [15] By allowing customers to \"visualize furniture in their own homes,\" the app \"boosts confidence\". [21] This confidence translates directly into a critical financial impact: \"lower returns\". [21] Given the immense logistical and financial cost of \"reverse logistics\" (handling, shipping, and processing returned furniture), this risk-reduction function is a major, though often unquantified, driver of net profitability.</p>"},{"location":"Marktstrategie%20%26%20Analyse/Konkurrenzanalyse/Ikea/#customer-satisfaction-the-finnish-market-anomaly","title":"Customer Satisfaction: The Finnish Market Anomaly","text":"<p>A 2024 academic study on IKEA's customization in the Finnish market provides a critical, nuanced view of this market impact. [22] The study found:</p> <ul> <li>High Satisfaction: Overall satisfaction with IKEA's customization services is exceptionally high, scoring 4.61 out of 5. The \"ease of use of digital tools\" was identified as the strongest predictor of this high satisfaction, with a beta coefficient (\u03b2) of 0.4222. [22]</li> <li>Mediocre Advocacy: Despite this high satisfaction, the Net Promoter Score (NPS) was a moderate 16.5. [22]</li> </ul> <p>This discrepancy reveals a critical \"omni-channel disconnect.\" The digital tool is performing exceptionally, successfully creating demand and high user satisfaction. However, this positive impact is being undermined by failures in offline fulfillment. The study notes that shoppers can spend hours perfecting a design online, only to find items \"out of stock or incompatible\" when they visit the physical store. [22] This disconnect destroys brand advocacy (NPS) and highlights that the digital tool's ultimate market impact is inextricably tethered to the performance of the entire supply chain.</p>"},{"location":"Marktstrategie%20%26%20Analyse/Konkurrenzanalyse/Ikea/#table-2-quantifiable-market-impacts-of-ikeas-digital-engagement-tools","title":"Table 2: Quantifiable Market Impacts of IKEA's Digital Engagement Tools","text":"Metric Value / Finding Context Source(s) AR-User Conversion Rate Lift 90% Conversion rate for users engaging with AR vs. those who do not. 19 Annual Kitchen Project Pipeline 1.75 Million Strategic goal for the new 3D kitchen planner. Represents captured, high-intent leads. 8 Strategic Sales Goal +10% by FY26 Target increase for the cooking and eating range, supported by the new planner. 8 Customer Satisfaction (Finland) 4.61 / 5.0 Overall satisfaction with customization services. \"Ease of digital tools\" is the strongest predictor. 22 Net Promoter Score (NPS) (Finland) 16.5 A moderate score, indicating high satisfaction is not translating to brand advocacy. 22 Financial Impact (Inferred) \"Lower returns\" AR/VR tools boost confidence, reducing uncertainty and costly product returns. 21"},{"location":"Marktstrategie%20%26%20Analyse/Konkurrenzanalyse/Ikea/#vi-operational-and-supply-chain-implications","title":"VI. Operational and Supply Chain Implications","text":"<p>The most sophisticated market impact of the IKEA configurator is its deep integration into back-end operations and supply chain intelligence, transforming it from a sales tool into an intelligence asset.</p>"},{"location":"Marktstrategie%20%26%20Analyse/Konkurrenzanalyse/Ikea/#the-kitchen-problem-hundreds-of-articles-one-forecast","title":"The \"Kitchen Problem\": Hundreds of Articles, One Forecast","text":"<p>The kitchen is IKEA's most complex product. A single kitchen sale \"consists of hundreds of different articles\". [23] For a supply chain, this is a forecasting nightmare. Historically, IKEA's systems had \"no feature to compensate for such effects,\" meaning the demand for a cabinet, its hinges, its handle, and its door were not dynamically linked. [23] This creates massive inefficiencies.</p>"},{"location":"Marktstrategie%20%26%20Analyse/Konkurrenzanalyse/Ikea/#the-planner-as-a-data-capture-engine","title":"The Planner as a Data-Capture Engine","text":"<p>IKEA's solution is a new AI-powered \"Demand Sensing\" tool designed to \"significantly improve the accuracy of its demand forecasting\". [24] This AI, like all AI, requires a massive, continuous, and high-quality data stream to function.</p> <p>This is where the configurator's role becomes clear. The 1.75 million annual kitchen projects [8] are not just sales leads; they are structured data feeds. Every time a user \"co-creates\" their dream kitchen, they are voluntarily building a perfect, itemized, future-dated purchase order. This user-generated data provides the \"invaluable insights\" [25] that fuel the Demand Sensing AI. The planner transforms the customer's \"play\" into a structured data input that allows IKEA to \"understand the demand\" for its \"billions of products\" [24] months in advance, creating an unassailable informational advantage.</p>"},{"location":"Marktstrategie%20%26%20Analyse/Konkurrenzanalyse/Ikea/#the-planner-as-a-labor-optimization-tool","title":"The Planner as a Labor Optimization Tool","text":"<p>In addition to its data function, the planner has a direct, operational impact on labor efficiency. A stated strategic goal of the new 3D planner is \"significantly reducing times for appointments\". [8] The planner achieves this by shifting labor from paid staff to unpaid customers.</p> <p>The \"labor\" that creates the \"IKEA Effect\" (Section III) also saves IKEA money. The customer performs the low-value, time-consuming work (basic layout, measuring, color choice). This frees IKEA co-workers to \"better focus on personalised service\". [8] The co-worker is elevated from a data-entry clerk to a high-value verifier and closer, guiding a pre-qualified customer through the final purchase. [26] This is a brilliant fusion of psychological engagement and operational efficiency.</p>"},{"location":"Marktstrategie%20%26%20Analyse/Konkurrenzanalyse/Ikea/#vii-frictions-and-frontiers-socio-cultural-and-user-adoption-barriers","title":"VII. Frictions and Frontiers: Socio-Cultural and User-Adoption Barriers","text":"<p>A comprehensive analysis must also acknowledge the tool's significant limitations, which define the frontiers of its market impact. The configurator's impact is neither universal nor universally positive.</p>"},{"location":"Marktstrategie%20%26%20Analyse/Konkurrenzanalyse/Ikea/#technical-failures-the-last-foot-problem","title":"Technical Failures: The \"Last Foot\" Problem","text":"<p>The planner's greatest weakness is the gap between its digital precision and the physical world's imprecision. The tool cannot see \"plumbing layout, uneven walls, low ceilings, or that quirky corner\". [27] Professional remodelers warn that \"perfect\" IKEA designs often \"don't actually fit\". [27]</p> <p>This is not a hypothetical problem. User reports document discoveries that their planner-generated designs were \"significantly off\" by 10 to 12 inches, requiring a full order cancellation and refund. [28] In other cases, installation teams have rejected plans created by both users and in-store planners, citing design-rule violations the software missed. [29] This \"last foot\" problem can be catastrophic, eroding all the trust and value built by the tool and spawning a cottage industry of third-party designers who specialize in fixing IKEA-generated plans.</p>"},{"location":"Marktstrategie%20%26%20Analyse/Konkurrenzanalyse/Ikea/#socio-cultural-mismatches-the-china-open-kitchen-case","title":"Socio-Cultural Mismatches: The China \"Open-Kitchen\" Case","text":"<p>An academic paper in Human-Computer Interaction (HCI) research highlights a more subtle, but profound, limitation: the planner is culturally opinionated. [30] The tool is embedded with a Nordic cultural value that the kitchen is a social, open-plan space. [30]</p> <p>This is identified as a \"major drawback\" for Chinese users. [30] In China, cultural traditions and cooking styles (like stir-frying) demand a \"closed-up space\" that is functional and \"low in social function\". [30] IKEA's attempt to \"force their own lifestyles and ideologies\" [30] via the planner's default templates creates a socio-cultural friction that leads to user rejection. This case study proves the configurator's market impact is culturally contingent and cannot be universally appliedTable 1: Evolution of IKEA's Digital Configurator Suite without careful localization of its core ideology, not just its language.</p>"},{"location":"Marktstrategie%20%26%20Analyse/Konkurrenzanalyse/Ikea/#user-adoption-barriers-the-touch-and-trust-deficit","title":"User-Adoption Barriers: The \"Touch and Trust\" Deficit","text":"<p>Finally, qualitative research on the AR \"IKEA Place\" app identifies key user-side adoption barriers [31]:</p> <ul> <li>Trust: Users expressed \"privacy and security issues\" about an app that, by necessity, must \"scan their private surroundings\". [31]</li> <li>Touch: For expensive, high-stakes items like a sofa, the AR tool was deemed insufficient. As one participant stated, \"I want to feel the material, I want to feel how the cushions are\". [31]</li> </ul> <p>These \"touch and trust\" deficits reveal the true omni-channel strategy. The digital tools cannot and are not meant to replace the physical store. They work in tandem with it. The digital tools educate, inspire, and pre-qualify the customer, but the \"last-mile\" of the sale\u2014feeling the cushion, getting expert validation, and building trust\u2014still drives traffic to IKEA's physical locations. [32]</p>"},{"location":"Marktstrategie%20%26%20Analyse/Konkurrenzanalyse/Ikea/#table-3-analysis-of-tool-specific-limitations-and-market-barriers","title":"Table 3: Analysis of Tool-Specific Limitations and Market Barriers","text":"Barrier Type Specific Example Business Implication Source(s) Technical / Operational Planner fails to account for real-world plumbing, uneven walls, or low ceilings. Leads to costly installation errors, order cancellations, and erosion of customer trust. 27 Socio-Cultural \"Open-kitchen\" template ideology embedded in the planner conflicts with Chinese cultural needs for a \"closed-up\" functional kitchen. Limits market penetration and adoption; results in user-base rejection. 30 User Adoption (AR) Privacy concerns with room-scanning; \"Need-to-touch\" for expensive items (e.g., sofas). Creates friction for data-gathering; reinforces the necessity of physical stores for \"last-mile\" sensory validation. 31 Omni-Channel \"Disconnects between online planning and offline fulfilment\" (e.g., out-of-stock items). High satisfaction with the tool, but low advocacy (NPS) for the brand. 22"},{"location":"Marktstrategie%20%26%20Analyse/Konkurrenzanalyse/Ikea/#viii-strategic-synthesis-and-competitive-outlook","title":"VIII. Strategic Synthesis and Competitive Outlook","text":"<p>The IKEA configurator suite is arguably one of the most successful and deeply integrated digital retail platforms in the non-tech world. It is not a \"feature\" but the linchpin of IKEA's entire market-driving strategy. [34]</p> <p>Its true market impact is the creation of a powerful, self-reinforcing virtuous cycle that blurs the lines between marketing, operations, and human psychology:</p> <ul> <li>It Gamifies Labor: The planners (especially Kreativ) turn the friction of home design into an engaging game. [8]</li> <li>Labor Creates Value: This \"play\" is a form of labor, which triggers the \"IKEA Effect\" [7] and its neural correlates (L-MFG activation) [9], building psychological attachment and higher valuation before a single dollar is spent.</li> <li>Value Drives Conversion: This psychological attachment, combined with the risk reduction of AR/AI visualization [13], \"boosts confidence\" [21] and leads to quantifiably higher conversion rates (a +90% lift for AR users) [19] and lower profit-eroding returns. [21]</li> <li>Conversion Creates Data: This mass-market engagement generates a massive, high-fidelity data pipeline (1.75 million kitchen projects annually). [8]</li> <li>Data Optimizes Operations: This data is the \"invaluable insight\" [25] that fuels IKEA's core AI \"Demand Sensing\" tool [24], solving its most complex supply chain forecasting problem.</li> </ul> <p>In conclusion, the IKEA configurator's greatest market impact is that it has successfully transformed the customer into its most effective psychological marketing tool, its most efficient operational co-worker, and its most prescient business intelligence analyst.</p>"},{"location":"Marktstrategie%20%26%20Analyse/Konkurrenzanalyse/Ikea/#works-cited","title":"Works cited","text":"<ol> <li>Full article: The changing marketing orientation within the business model of an international retailer \u2013 IKEA in China over 10 years</li> <li>Customer Co-creation and Dynamic Capabilities</li> <li>Leveraging brand co-creation in a digital era: An IKEA case study</li> <li>Journal of Economics and Management Customer knowledge in (co)creation of product. A case study of IKEA</li> <li>Design incorporated: IKEA as personal experience</li> <li>From Product Design to Customer Care: IKEA's Blueprint for Success</li> <li>The \"IKEA Effect\": When Labor Leads to Love</li> <li>The new IKEA 3D kitchen planning experience brings 1.75 million design projects to life each year</li> <li>Visualizing the IKEA effect: experiential consumption assessed with...</li> <li>Does Ikea Kitchen Planner Actually Work???? - Houzz</li> <li>Plan your dream kitchen - IKEA</li> <li>IKEA Kitchen Design Tool Explained - Create Your Dream Kitchen</li> <li>Launch of new IKEA Place app</li> <li>How IKEA's app nails omnichannel UX (and what brands can learn)</li> <li>IKEA: The omnichannel strategy the Swedish furniture retailer used to reach the top</li> <li>IKEA launches new AI-powered, digital experience empowering customers to create lifelike room designs</li> <li>IKEA launches new AI-powered experience; IKEA Kreativ</li> <li>Reimagine Your Home with IKEA Kreativ</li> <li>IKEA: A Case Study on the impact of AR and VR on Marketing</li> <li>How IKEA Uses Technology to Improve Customer Experience (CX) in Retail</li> <li>IKEA Place: AR is Transforming the Future of Retail</li> <li>Assessing the impact of product customization on...</li> <li>The impact of omni-channel retailing on demand planning for new products at IKEA</li> <li>Using AI for smarter demand forecasting</li> <li>IKEA uses demand sensing to improve the customer offering</li> <li>Design a Kitchen - Kitchen Planning Services</li> <li>10 Surprising Reasons IKEA Kitchen Planner Isn't Enough</li> <li>Our Ikea Kitchen Story.... Or Nightmare - Reddit</li> <li>Kitchen Cabinetry Planning Issue - The planner messed up. : r/IKEA</li> <li>Designing Life: A Socio-cultural Analysis of IKEA</li> <li>Explore The Influence Of Augmented Reality On Consumer...</li> <li>IKEA's Oxford Street flagship signals a shift in furniture retail</li> <li>Avoid these 3 IKEA Kitchen Layout Plan mistakes</li> <li>A STUDY ON IKEA'S MARKETING STRATEGIES...</li> <li>Business leadership in the digital age: IKEA's story</li> </ol>"},{"location":"konfigurierbare%20Modelle/Anforderungen/","title":"Anforderungen","text":"<p>Diese Seite beschreibt die grundlegenden Anforderungen an die verschiedenen Modellvarianten der M\u00f6belmodule. Ziel ist es, vollst\u00e4ndig parametrisierte, industriell automatisierbare und einfach montierbare M\u00f6bel zu entwickeln.</p>"},{"location":"konfigurierbare%20Modelle/Anforderungen/#1-parametrik-variantenfahigkeit","title":"1. Parametrik &amp; Variantenf\u00e4higkeit","text":"<ul> <li>Das gesamte CAD-Modell muss 100 % parametrisch aufgebaut sein.</li> <li>Alle relevanten Ma\u00dfe m\u00fcssen \u00fcber Parameter steuerbar sein.</li> </ul>"},{"location":"konfigurierbare%20Modelle/Anforderungen/#11-user-parameter","title":"1.1 User-Parameter","text":"<p>Parameter, die direkt vom Nutzer im Konfigurator ver\u00e4ndert werden k\u00f6nnen:</p> <ul> <li>L\u00e4nge</li> <li>Breite</li> <li>H\u00f6he (Lounge und Esstisch H\u00f6he)</li> <li>Winkel der Enden (z. B. bei schiefen Balkonen oder nicht rechtwinkligen Einbausituationen)</li> <li>\u00d6ffnungsvarianten (z. B. fest, teilweise klappbar, Truhe)</li> </ul>"},{"location":"konfigurierbare%20Modelle/Anforderungen/#12-developer-parameter-dev-parameter","title":"1.2 Developer-Parameter (Dev-Parameter)","text":"<p>Interne Parameter zur Steuerung der Konstruktion:</p> <ul> <li>Brett- und Balkenquerschnitte</li> <li>Spaltma\u00dfe</li> <li>Profilh\u00f6hen und -breiten</li> <li>Materialst\u00e4rken</li> <li>Mindest- und Maximalabst\u00e4nde</li> <li>Fertigungstoleranzen</li> <li>...</li> </ul>"},{"location":"konfigurierbare%20Modelle/Anforderungen/#2-konstruktionsprinzip","title":"2. Konstruktionsprinzip","text":"<ul> <li>Die Konstruktion darf ausschlie\u00dflich aus Balken und Brettern bestehen.</li> <li>Alle Bauteile m\u00fcssen:</li> <li>mit standardisierten Querschnitten</li> <li>und einfachen Geometrien   gefertigt werden k\u00f6nnen.</li> <li>Keine Sonderteile, keine komplexen Freiformfl\u00e4chen.</li> </ul>"},{"location":"konfigurierbare%20Modelle/Anforderungen/#3-automatisierte-fertigung","title":"3. Automatisierte Fertigung","text":"<ul> <li>Alle Bauteile m\u00fcssen f\u00fcr eine 100 % automatisierte maschinelle Fertigung ausgelegt sein.</li> <li>Ziel:</li> <li>Minimierung der Fertigungskosten</li> <li>Skalierbarkeit</li> <li>On-Demand-Produktion nach Bestellungseingang</li> <li>M\u00f6glichst geringer Lagerbestand</li> </ul>"},{"location":"konfigurierbare%20Modelle/Anforderungen/#31-fertigungsanforderungen","title":"3.1 Fertigungsanforderungen","text":"<ul> <li>Zuschnitt vollst\u00e4ndig CNC- oder s\u00e4gebasiert</li> <li>Bohrungen, Nuten und Konturen maschinell erzeugbar</li> <li>Keine manuelle Nacharbeit notwendig</li> <li>Wiederholgenaue und reproduzierbare Geometrie</li> </ul>"},{"location":"konfigurierbare%20Modelle/Anforderungen/#4-montagefreundlichkeit-idiotensichere-montage","title":"4. Montagefreundlichkeit (\u201eIdiotensichere Montage\u201c)","text":"<p>Die Montage muss so einfach und fehlertolerant wie m\u00f6glich sein.</p>"},{"location":"konfigurierbare%20Modelle/Anforderungen/#41-montageprinzipien","title":"4.1 Montageprinzipien","text":"<ul> <li>Eindeutige Bauteilorientierung (kein Vertauschen m\u00f6glich)</li> <li>Klare Montageabfolge</li> <li>Keine Spezialwerkzeuge notwendig</li> </ul>"},{"location":"konfigurierbare%20Modelle/Anforderungen/#42-unterstutzende-manahmen","title":"4.2 Unterst\u00fctzende Ma\u00dfnahmen","text":"<ul> <li>Kennzeichnungen</li> <li>z. B. Lasergravuren mit Positionsnummern oder Symbolen</li> <li>Positionierungshilfen</li> <li>z. B. Abstandshalter</li> <li>Anschl\u00e4ge</li> <li>F\u00fchrungen</li> <li>Vorbereitete Verbindungen</li> <li>vorgebohrte L\u00f6cher</li> <li>Sackl\u00f6cher</li> <li>Steckverbindungen</li> <li>Steck- oder Schraubsysteme, die sich logisch selbst erkl\u00e4ren</li> </ul>"},{"location":"konfigurierbare%20Modelle/Anforderungen/#5-modularitat","title":"5. Modularit\u00e4t","text":"<ul> <li>Alle Modelle m\u00fcssen modular aufgebaut sein.</li> <li>Einzelne Module sollen:</li> <li>unabh\u00e4ngig gefertigt</li> <li>kombiniert</li> <li>ausgetauscht   werden k\u00f6nnen.</li> <li>Erweiterungen (z. B. zus\u00e4tzliche Felder) m\u00fcssen ohne Neukonstruktion m\u00f6glich sein.</li> </ul>"},{"location":"konfigurierbare%20Modelle/Anforderungen/#6-erweiterbarkeit","title":"6. Erweiterbarkeit","text":"<ul> <li>Neue Modellvarianten m\u00fcssen:</li> <li>auf der bestehenden Parametrik aufbauen</li> <li>ohne grundlegende Struktur\u00e4nderungen integrierbar sein</li> <li>Das System muss zuk\u00fcnftige Anforderungen (z. B. neue Materialien, neue \u00d6ffnungsarten) unterst\u00fctzen.</li> </ul>"},{"location":"konfigurierbare%20Modelle/Anforderungen/#7-dokumentation-nachvollziehbarkeit","title":"7. Dokumentation &amp; Nachvollziehbarkeit","text":"<ul> <li>Alle Parameter m\u00fcssen:</li> <li>eindeutig benannt</li> <li>logisch gruppiert</li> <li>dokumentiert   sein.</li> <li>Die Konstruktion soll f\u00fcr Dritte (z. B. neue Entwickler) verst\u00e4ndlich und wartbar sein.</li> </ul>"},{"location":"konfigurierbare%20Modelle/Verbindungen%20und%20Montagehilfen/","title":"Verbindungen und Montagehilfen","text":"<p>Diese Seite beschreibt die m\u00f6glichen Verbindungsarten zwischen den einzelnen Modulen sowie unterst\u00fctzende Montagehilfen. Bewertet werden die Verbindungen hinsichtlich Montageaufwand, Steifigkeit, Fertigungstauglichkeit und Eignung f\u00fcr eine automatisierte Produktion.</p>"},{"location":"konfigurierbare%20Modelle/Verbindungen%20und%20Montagehilfen/#1-anforderungen-an-verbindungen","title":"1. Anforderungen an Verbindungen","text":"<p>Alle Verbindungen m\u00fcssen folgende Grundanforderungen erf\u00fcllen:</p> <ul> <li>Geeignet f\u00fcr serielle und automatisierte Fertigung</li> <li>M\u00f6glichst werkzeugarm oder werkzeuglos montierbar</li> <li>Hohe Wiederholgenauigkeit</li> <li>Ausreichende Steifigkeit f\u00fcr M\u00f6belanwendungen</li> <li>Fehlermontage muss entweder verhindert oder offensichtlich sein</li> </ul>"},{"location":"konfigurierbare%20Modelle/Verbindungen%20und%20Montagehilfen/#2-klassische-schraubverbindungen","title":"2. Klassische Schraubverbindungen","text":""},{"location":"konfigurierbare%20Modelle/Verbindungen%20und%20Montagehilfen/#21-beschreibung","title":"2.1 Beschreibung","text":"<ul> <li>Verbindung \u00fcber Holzschrauben oder metrische Schrauben</li> <li>Typischer Einsatz an:</li> <li>Ecken</li> <li>Rahmenverbindungen</li> <li>Modul\u00fcberg\u00e4ngen</li> </ul>"},{"location":"konfigurierbare%20Modelle/Verbindungen%20und%20Montagehilfen/#22-vorteile","title":"2.2 Vorteile","text":"<ul> <li>Hohe Steifigkeit</li> <li>Gut bekannt und akzeptiert</li> <li>Einfach zu berechnen und zu dimensionieren</li> <li>L\u00f6sbar (Demontage m\u00f6glich)</li> <li>Toleranzunempfindlich</li> </ul>"},{"location":"konfigurierbare%20Modelle/Verbindungen%20und%20Montagehilfen/#23-nachteile","title":"2.3 Nachteile","text":"<ul> <li>H\u00f6herer Montageaufwand</li> <li>Gefahr von Montagefehlern (falsche Schraube, falsche Position)</li> <li>Optisch sichtbar (sofern nicht verdeckt)</li> <li>Schrauben k\u00f6nnen sich mit der Zeit l\u00f6sen</li> </ul>"},{"location":"konfigurierbare%20Modelle/Verbindungen%20und%20Montagehilfen/#24-fertigung-automatisierung","title":"2.4 Fertigung &amp; Automatisierung","text":"<ul> <li>Gut geeignet f\u00fcr automatisierte Vorbohrprozesse</li> <li>Schraubmontage kann teilautomatisiert werden</li> <li>Positionierung der Teile muss dennoch exakt erfolgen</li> </ul>"},{"location":"konfigurierbare%20Modelle/Verbindungen%20und%20Montagehilfen/#3-steckverbindungen-federnut","title":"3. Steckverbindungen (Feder\u2013Nut)","text":""},{"location":"konfigurierbare%20Modelle/Verbindungen%20und%20Montagehilfen/#31-beschreibung","title":"3.1 Beschreibung","text":"<ul> <li>Formschl\u00fcssige Verbindung \u00fcber:</li> <li>Feder-Nut-Systeme</li> <li>Zapfen</li> <li>Schwalbenschwanz-\u00e4hnliche Geometrien (vereinfacht)</li> <li>Module werden ineinandergesteckt und ggf. zus\u00e4tzlich fixiert</li> </ul>"},{"location":"konfigurierbare%20Modelle/Verbindungen%20und%20Montagehilfen/#32-vorteile","title":"3.2 Vorteile","text":"<ul> <li>Sehr schnelle Montage</li> <li>Intuitive, \u201eselbsterkl\u00e4rende\u201c Verbindung</li> <li>Gute Wiederholgenauigkeit</li> <li>Ideal f\u00fcr modulare Systeme</li> <li>Gute Positionierung der Bauteile zueinander</li> </ul>"},{"location":"konfigurierbare%20Modelle/Verbindungen%20und%20Montagehilfen/#33-nachteile","title":"3.3 Nachteile","text":"<ul> <li>H\u00f6here Anforderungen an Fertigungsgenauigkeit</li> <li>Geringere Toleranzen</li> <li>Je nach Ausf\u00fchrung geringere Steifigkeit ohne Zusatzfixierung</li> <li>Aufw\u00e4ndiger in der Konstruktion</li> </ul>"},{"location":"konfigurierbare%20Modelle/Verbindungen%20und%20Montagehilfen/#34-fertigung-automatisierung","title":"3.4 Fertigung &amp; Automatisierung","text":"<ul> <li>Sehr gut CNC-geeignet</li> <li>Ideal f\u00fcr automatisierte Fr\u00e4sprozesse</li> <li>Hohe Anforderungen an Ma\u00dfhaltigkeit</li> <li>Kaum manuelle Nacharbeit m\u00f6glich</li> </ul>"},{"location":"konfigurierbare%20Modelle/Verbindungen%20und%20Montagehilfen/#4-dubelverbindungen","title":"4. D\u00fcbelverbindungen","text":""},{"location":"konfigurierbare%20Modelle/Verbindungen%20und%20Montagehilfen/#41-beschreibung","title":"4.1 Beschreibung","text":"<ul> <li>Verbindung \u00fcber Holzd\u00fcbel oder Systemd\u00fcbel</li> <li>Typisch f\u00fcr fl\u00e4chige oder rechtwinklige Verbindungen</li> </ul>"},{"location":"konfigurierbare%20Modelle/Verbindungen%20und%20Montagehilfen/#42-vorteile","title":"4.2 Vorteile","text":"<ul> <li>Unsichtbare Verbindung</li> <li>Gute Selbstpositionierung</li> <li>Saubere Optik</li> <li>Gute Wiederholgenauigkeit</li> </ul>"},{"location":"konfigurierbare%20Modelle/Verbindungen%20und%20Montagehilfen/#43-nachteile","title":"4.3 Nachteile","text":"<ul> <li>Nicht selbsttragend w\u00e4hrend der Montage</li> <li>Zus\u00e4tzliche Fixierung oft n\u00f6tig (z. B. Schrauben oder Leim)</li> <li>Leimverbindungen nicht demontierbar</li> <li>Montageanf\u00e4lliger bei Ma\u00dfabweichungen</li> </ul>"},{"location":"konfigurierbare%20Modelle/Verbindungen%20und%20Montagehilfen/#44-fertigung-automatisierung","title":"4.4 Fertigung &amp; Automatisierung","text":"<ul> <li>Sehr gut automatisierbar (Bohrungen)</li> <li>Pr\u00e4zise Positionierung notwendig</li> <li>Ideal f\u00fcr Serienfertigung</li> <li>Leimauftrag erh\u00f6ht Prozesskomplexit\u00e4t</li> </ul>"},{"location":"konfigurierbare%20Modelle/Verbindungen%20und%20Montagehilfen/#5-kombination-von-verbindungsarten","title":"5. Kombination von Verbindungsarten","text":"<p>In vielen F\u00e4llen ist eine Kombination mehrerer Verbindungsarten sinnvoll:</p> <ul> <li>Steckverbindung zur Positionierung</li> <li>Schraube zur Sicherung und Steifigkeit</li> <li>D\u00fcbel zur optischen Verbesserung</li> </ul>"},{"location":"konfigurierbare%20Modelle/Verbindungen%20und%20Montagehilfen/#beispiele","title":"Beispiele:","text":"<ul> <li>Feder\u2013Nut + Schraube (verdeckt)</li> <li>D\u00fcbel + Schraube</li> <li>Stecksystem + Sicherungsschraube</li> </ul>"},{"location":"konfigurierbare%20Modelle/Verbindungen%20und%20Montagehilfen/#6-montagehilfen","title":"6. Montagehilfen","text":""},{"location":"konfigurierbare%20Modelle/Verbindungen%20und%20Montagehilfen/#61-ziel","title":"6.1 Ziel","text":"<p>Montagehilfen sollen:</p> <ul> <li>Montagefehler verhindern</li> <li>Die Montagezeit reduzieren</li> <li>Eine klare Montageabfolge erzwingen</li> </ul>"},{"location":"konfigurierbare%20Modelle/Verbindungen%20und%20Montagehilfen/#62-arten-von-montagehilfen","title":"6.2 Arten von Montagehilfen","text":"<ul> <li>Mechanische Positionierungshilfen</li> <li>Anschl\u00e4ge</li> <li>Abstandshalter</li> <li>F\u00fchrungsnuten</li> <li>Visuelle Kennzeichnungen</li> <li>Lasergravierte Markierungen</li> <li>Nummerierungen</li> <li>Symbole</li> <li>Konstruktive Zwangsf\u00fchrung</li> <li>Teile passen nur in einer Orientierung</li> <li>Asymmetrische Geometrien</li> <li>Vorgefertigte Bohrungen</li> <li>Reduzieren Fehler</li> <li>Erh\u00f6hen Wiederholgenauigkeit</li> </ul>"},{"location":"konfigurierbare%20Modelle/Verbindungen%20und%20Montagehilfen/#7-bewertungskriterien-ubersicht","title":"7. Bewertungskriterien (\u00dcbersicht)","text":"Verbindungstyp Montageaufwand Steifigkeit Automatisierung Demontierbar Schrauben Mittel Hoch Gut Ja Feder\u2013Nut Sehr gering Mittel Sehr gut Bedingt D\u00fcbel Mittel Mittel Sehr gut Nein / bedingt"},{"location":"konfigurierbare%20Modelle/Verbindungen%20und%20Montagehilfen/#8-fazit","title":"8. Fazit","text":"<p>F\u00fcr ein modular aufgebautes, industriell gefertigtes M\u00f6belsystem sind:</p> <ul> <li>Steckverbindungen ideal f\u00fcr schnelle, fehlerarme Montage</li> <li>Schraubverbindungen sinnvoll zur Sicherung und Steifigkeit</li> <li>D\u00fcbelverbindungen besonders f\u00fcr optisch anspruchsvolle Bereiche geeignet</li> </ul> <p>Die optimale L\u00f6sung ist meist eine hybride Verbindung, abgestimmt auf: - Montageziel - Belastung - Fertigungskonzept</p>"}]}